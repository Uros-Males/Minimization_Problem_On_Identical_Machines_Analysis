{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNHpravIASiRGoQNCfvIEnR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uros-Males/Minimization_Problem_On_Identical_Machines_Analysis/blob/main/4Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YiQcuNkDxHUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d96509f-b37f-4ae2-c820-376f96bd4e57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8750\n"
          ]
        }
      ],
      "source": [
        "#IN PROGRESS....\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import time\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/C-instances-runtime-analysis.csv')\n",
        "print(df.shape[0])\n",
        "\n",
        "shuffled = df.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = ['y', 'index', 'inst.name','type', 'CPLEXStatus']\n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_modified = X.drop([ 'median', 'range',  'max','av.length', 'min','indeks', 'class',  'subtype', '(m/n)^3', '(m/n)^2', '(n/m)^2', '(n/m)^3','m/n','m'], axis = 1)\n",
        "print(X_modified.head())\n",
        "#X_modified = X.drop(['max', 'n/m', '(n/m)^2', '(n/m)^3', 'm/n', '(m/n)^2', '(m/n)^3', 'class', 'av.length'], axis = 1)"
      ],
      "metadata": {
        "id": "Jzlk_oaRyQjm",
        "outputId": "6a8c47f9-1ee1-453a-ff9f-02d1a4ad79d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     n  n/m    std.dev   k\n",
            "0  162  9.0  22.889069  69\n",
            "1   20  2.0  21.974329  17\n",
            "2   54  3.0  51.808578  46\n",
            "3   90  4.5  15.815685  43\n",
            "4  180  9.0  15.707343  50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Dropout,BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras \n",
        "\n",
        "\n",
        "def custom_activation(x):\n",
        "    #return K.relu(tensorflow.subtract(x,-1)) - K.relu(tensorflow.subtract(x,1))\n",
        "    return 99999*1/(1+K.exp(-x))\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(8, input_dim=X_modified.shape[1], activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "\n",
        "    #classifier.add(Dense(32, activation = 'relu'))\n",
        "    #classifier.add(Dense(32, activation = 'relu'))\n",
        "    #classifier.add(Dense(16, activation = 'relu'))\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    \n",
        "    model.add(Dense(1, activation = custom_activation))\n",
        "    #model.add(Activation(custom_activation, name='SpecialActivation'))\n",
        "    model.compile(loss='mean_squared_error', optimizer=tensorflow.keras.optimizers.Adam(clipnorm=1))\n",
        "    #model.compile(loss='mean_squared_error', optimizer='RMSProp')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7_m2qFDRya94"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc2 = StandardScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y, random_state=0, train_size = 0.83)\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#y_train = sc2.fit_transform(y_train.values.reshape(-1,1))\n",
        "#y_test = sc2.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "estimator = KerasRegressor(build_fn=make_model, epochs=800, batch_size=32, verbose=1)\n",
        "\n",
        "#history=estimator.fit(X_train,y_train)\n",
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 50, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = estimator.fit(X_train, y_train, validation_data =(X_test, y_test), \n",
        "                    callbacks =[earlystopping])\n",
        "#plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JHin8gI5ftQ",
        "outputId": "09edcb90-0894-4947-cf5b-22de4fa6071c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "227/227 [==============================] - 4s 8ms/step - loss: 787882176.0000 - val_loss: 370308928.0000\n",
            "Epoch 2/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 358744352.0000 - val_loss: 329451968.0000\n",
            "Epoch 3/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 347008832.0000 - val_loss: 335833760.0000\n",
            "Epoch 4/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 343088832.0000 - val_loss: 323231712.0000\n",
            "Epoch 5/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 335003520.0000 - val_loss: 366456928.0000\n",
            "Epoch 6/800\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 338825856.0000 - val_loss: 323178944.0000\n",
            "Epoch 7/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 341501376.0000 - val_loss: 326858432.0000\n",
            "Epoch 8/800\n",
            "227/227 [==============================] - 2s 8ms/step - loss: 330611712.0000 - val_loss: 352988480.0000\n",
            "Epoch 9/800\n",
            "227/227 [==============================] - 2s 8ms/step - loss: 332260672.0000 - val_loss: 310370176.0000\n",
            "Epoch 10/800\n",
            "227/227 [==============================] - 2s 8ms/step - loss: 321819744.0000 - val_loss: 311550272.0000\n",
            "Epoch 11/800\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 328128352.0000 - val_loss: 319098208.0000\n",
            "Epoch 12/800\n",
            "227/227 [==============================] - 2s 9ms/step - loss: 320717760.0000 - val_loss: 321490624.0000\n",
            "Epoch 13/800\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 316972064.0000 - val_loss: 311344096.0000\n",
            "Epoch 14/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 322030048.0000 - val_loss: 369008384.0000\n",
            "Epoch 15/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 320709856.0000 - val_loss: 315830176.0000\n",
            "Epoch 16/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 334117696.0000 - val_loss: 327523776.0000\n",
            "Epoch 17/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 313013376.0000 - val_loss: 317636384.0000\n",
            "Epoch 18/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 311274528.0000 - val_loss: 328096032.0000\n",
            "Epoch 19/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 308985024.0000 - val_loss: 312009504.0000\n",
            "Epoch 20/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 303580224.0000 - val_loss: 321879968.0000\n",
            "Epoch 21/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 305235584.0000 - val_loss: 333047616.0000\n",
            "Epoch 22/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 301290528.0000 - val_loss: 326649248.0000\n",
            "Epoch 23/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 305147104.0000 - val_loss: 353527776.0000\n",
            "Epoch 24/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 292437600.0000 - val_loss: 350173408.0000\n",
            "Epoch 25/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 297548000.0000 - val_loss: 303755840.0000\n",
            "Epoch 26/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 280565920.0000 - val_loss: 319468320.0000\n",
            "Epoch 27/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 282218272.0000 - val_loss: 304044800.0000\n",
            "Epoch 28/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 282279104.0000 - val_loss: 324329888.0000\n",
            "Epoch 29/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 284478912.0000 - val_loss: 290356896.0000\n",
            "Epoch 30/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 281212064.0000 - val_loss: 327375424.0000\n",
            "Epoch 31/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 278239008.0000 - val_loss: 294994816.0000\n",
            "Epoch 32/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 276639776.0000 - val_loss: 300523968.0000\n",
            "Epoch 33/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 287530752.0000 - val_loss: 331079648.0000\n",
            "Epoch 34/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267945792.0000 - val_loss: 310931456.0000\n",
            "Epoch 35/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 279547584.0000 - val_loss: 308892096.0000\n",
            "Epoch 36/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 275899776.0000 - val_loss: 286769536.0000\n",
            "Epoch 37/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267049584.0000 - val_loss: 286622784.0000\n",
            "Epoch 38/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 275683360.0000 - val_loss: 313097568.0000\n",
            "Epoch 39/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270539552.0000 - val_loss: 290503200.0000\n",
            "Epoch 40/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 271143008.0000 - val_loss: 297232864.0000\n",
            "Epoch 41/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 271167232.0000 - val_loss: 303405664.0000\n",
            "Epoch 42/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269637216.0000 - val_loss: 336563040.0000\n",
            "Epoch 43/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 275740352.0000 - val_loss: 302888352.0000\n",
            "Epoch 44/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267988656.0000 - val_loss: 359872928.0000\n",
            "Epoch 45/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 276538400.0000 - val_loss: 305034016.0000\n",
            "Epoch 46/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270381472.0000 - val_loss: 301978464.0000\n",
            "Epoch 47/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 265827424.0000 - val_loss: 287872416.0000\n",
            "Epoch 48/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267314752.0000 - val_loss: 333034016.0000\n",
            "Epoch 49/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272783328.0000 - val_loss: 299761408.0000\n",
            "Epoch 50/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 268134800.0000 - val_loss: 303613824.0000\n",
            "Epoch 51/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 281944480.0000 - val_loss: 317584416.0000\n",
            "Epoch 52/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 274991232.0000 - val_loss: 353600576.0000\n",
            "Epoch 53/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 288970912.0000 - val_loss: 305002304.0000\n",
            "Epoch 54/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263283824.0000 - val_loss: 293966752.0000\n",
            "Epoch 55/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 275933664.0000 - val_loss: 290752992.0000\n",
            "Epoch 56/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 277500064.0000 - val_loss: 302538208.0000\n",
            "Epoch 57/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 275116288.0000 - val_loss: 301174624.0000\n",
            "Epoch 58/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267366544.0000 - val_loss: 348277664.0000\n",
            "Epoch 59/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272464096.0000 - val_loss: 290094848.0000\n",
            "Epoch 60/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 275390336.0000 - val_loss: 304003456.0000\n",
            "Epoch 61/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 274299552.0000 - val_loss: 309754496.0000\n",
            "Epoch 62/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272489088.0000 - val_loss: 290844128.0000\n",
            "Epoch 63/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 274528384.0000 - val_loss: 309023840.0000\n",
            "Epoch 64/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267339792.0000 - val_loss: 299704384.0000\n",
            "Epoch 65/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269181792.0000 - val_loss: 311616768.0000\n",
            "Epoch 66/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 259553840.0000 - val_loss: 301063328.0000\n",
            "Epoch 67/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269307136.0000 - val_loss: 314156736.0000\n",
            "Epoch 68/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 275812480.0000 - val_loss: 304373504.0000\n",
            "Epoch 69/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 283459488.0000 - val_loss: 289373952.0000\n",
            "Epoch 70/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267943744.0000 - val_loss: 306545248.0000\n",
            "Epoch 71/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 274192640.0000 - val_loss: 298613696.0000\n",
            "Epoch 72/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 260651952.0000 - val_loss: 285633696.0000\n",
            "Epoch 73/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267258208.0000 - val_loss: 295910592.0000\n",
            "Epoch 74/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 259615920.0000 - val_loss: 297368800.0000\n",
            "Epoch 75/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 265345088.0000 - val_loss: 299317920.0000\n",
            "Epoch 76/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 266759392.0000 - val_loss: 293458784.0000\n",
            "Epoch 77/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 264802896.0000 - val_loss: 287527552.0000\n",
            "Epoch 78/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263650608.0000 - val_loss: 288822336.0000\n",
            "Epoch 79/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267669120.0000 - val_loss: 308622176.0000\n",
            "Epoch 80/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263635712.0000 - val_loss: 337863328.0000\n",
            "Epoch 81/800\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 274907776.0000 - val_loss: 300602240.0000\n",
            "Epoch 82/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267791488.0000 - val_loss: 343615296.0000\n",
            "Epoch 83/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269156352.0000 - val_loss: 336269856.0000\n",
            "Epoch 84/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 271518400.0000 - val_loss: 333501120.0000\n",
            "Epoch 85/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 259495472.0000 - val_loss: 300123296.0000\n",
            "Epoch 86/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 266000048.0000 - val_loss: 294498752.0000\n",
            "Epoch 87/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 264269536.0000 - val_loss: 296305024.0000\n",
            "Epoch 88/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263462656.0000 - val_loss: 291177280.0000\n",
            "Epoch 89/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 265883344.0000 - val_loss: 312029440.0000\n",
            "Epoch 90/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 268501056.0000 - val_loss: 319688960.0000\n",
            "Epoch 91/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267899568.0000 - val_loss: 349604832.0000\n",
            "Epoch 92/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263379776.0000 - val_loss: 294504480.0000\n",
            "Epoch 93/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 268298432.0000 - val_loss: 329779520.0000\n",
            "Epoch 94/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 266959856.0000 - val_loss: 300285856.0000\n",
            "Epoch 95/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 268139184.0000 - val_loss: 304521088.0000\n",
            "Epoch 96/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270461792.0000 - val_loss: 308378528.0000\n",
            "Epoch 97/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 280988672.0000 - val_loss: 328473184.0000\n",
            "Epoch 98/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 261038960.0000 - val_loss: 333314784.0000\n",
            "Epoch 99/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270789856.0000 - val_loss: 295817248.0000\n",
            "Epoch 100/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267413472.0000 - val_loss: 295416480.0000\n",
            "Epoch 101/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 262416336.0000 - val_loss: 287136928.0000\n",
            "Epoch 102/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 266870704.0000 - val_loss: 306554624.0000\n",
            "Epoch 103/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270829568.0000 - val_loss: 293859424.0000\n",
            "Epoch 104/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 273282336.0000 - val_loss: 287557856.0000\n",
            "Epoch 105/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270842816.0000 - val_loss: 297222528.0000\n",
            "Epoch 106/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263785488.0000 - val_loss: 295635040.0000\n",
            "Epoch 107/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270417664.0000 - val_loss: 350773696.0000\n",
            "Epoch 108/800\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 268743424.0000 - val_loss: 302773664.0000\n",
            "Epoch 109/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 275011712.0000 - val_loss: 312032128.0000\n",
            "Epoch 110/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272884416.0000 - val_loss: 298641728.0000\n",
            "Epoch 111/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270809088.0000 - val_loss: 329461664.0000\n",
            "Epoch 112/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269355264.0000 - val_loss: 306959072.0000\n",
            "Epoch 113/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 265581488.0000 - val_loss: 304995968.0000\n",
            "Epoch 114/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 273594400.0000 - val_loss: 295058432.0000\n",
            "Epoch 115/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 265142528.0000 - val_loss: 288314144.0000\n",
            "Epoch 116/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 268028000.0000 - val_loss: 285635968.0000\n",
            "Epoch 117/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 264430752.0000 - val_loss: 296821536.0000\n",
            "Epoch 118/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 264277936.0000 - val_loss: 342966528.0000\n",
            "Epoch 119/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269257600.0000 - val_loss: 311032768.0000\n",
            "Epoch 120/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272385056.0000 - val_loss: 296186112.0000\n",
            "Epoch 121/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267534272.0000 - val_loss: 274475264.0000\n",
            "Epoch 122/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 278721472.0000 - val_loss: 304114912.0000\n",
            "Epoch 123/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 271651200.0000 - val_loss: 286626464.0000\n",
            "Epoch 124/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267077840.0000 - val_loss: 300023552.0000\n",
            "Epoch 125/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263336368.0000 - val_loss: 313263520.0000\n",
            "Epoch 126/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267360400.0000 - val_loss: 306935072.0000\n",
            "Epoch 127/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263880800.0000 - val_loss: 319624256.0000\n",
            "Epoch 128/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267487968.0000 - val_loss: 294522912.0000\n",
            "Epoch 129/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267103888.0000 - val_loss: 343053024.0000\n",
            "Epoch 130/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263741440.0000 - val_loss: 335409696.0000\n",
            "Epoch 131/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270274304.0000 - val_loss: 323035680.0000\n",
            "Epoch 132/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 268738912.0000 - val_loss: 337045152.0000\n",
            "Epoch 133/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 268246272.0000 - val_loss: 297933600.0000\n",
            "Epoch 134/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269371776.0000 - val_loss: 325080480.0000\n",
            "Epoch 135/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 265129536.0000 - val_loss: 284762368.0000\n",
            "Epoch 136/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267263312.0000 - val_loss: 315072768.0000\n",
            "Epoch 137/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 275859456.0000 - val_loss: 330164832.0000\n",
            "Epoch 138/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 271621536.0000 - val_loss: 295650176.0000\n",
            "Epoch 139/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 266567344.0000 - val_loss: 321265568.0000\n",
            "Epoch 140/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272171360.0000 - val_loss: 277193088.0000\n",
            "Epoch 141/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 262453440.0000 - val_loss: 320056192.0000\n",
            "Epoch 142/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269122176.0000 - val_loss: 315720352.0000\n",
            "Epoch 143/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269709632.0000 - val_loss: 305943264.0000\n",
            "Epoch 144/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272642272.0000 - val_loss: 307164640.0000\n",
            "Epoch 145/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 276655616.0000 - val_loss: 343179872.0000\n",
            "Epoch 146/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 264731312.0000 - val_loss: 302194144.0000\n",
            "Epoch 147/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272623840.0000 - val_loss: 309538496.0000\n",
            "Epoch 148/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272107040.0000 - val_loss: 305708736.0000\n",
            "Epoch 149/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 266385152.0000 - val_loss: 292628384.0000\n",
            "Epoch 150/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 267534592.0000 - val_loss: 298101920.0000\n",
            "Epoch 151/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 268778304.0000 - val_loss: 283015328.0000\n",
            "Epoch 152/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 280116032.0000 - val_loss: 347651456.0000\n",
            "Epoch 153/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 282481632.0000 - val_loss: 276005760.0000\n",
            "Epoch 154/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 271631200.0000 - val_loss: 332178560.0000\n",
            "Epoch 155/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 281104768.0000 - val_loss: 316174144.0000\n",
            "Epoch 156/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 279103552.0000 - val_loss: 303683552.0000\n",
            "Epoch 157/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 286741920.0000 - val_loss: 344316800.0000\n",
            "Epoch 158/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 274028320.0000 - val_loss: 309884896.0000\n",
            "Epoch 159/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270764512.0000 - val_loss: 322495680.0000\n",
            "Epoch 160/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 269919936.0000 - val_loss: 303283712.0000\n",
            "Epoch 161/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 280474688.0000 - val_loss: 308156704.0000\n",
            "Epoch 162/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 278154048.0000 - val_loss: 300179712.0000\n",
            "Epoch 163/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263382400.0000 - val_loss: 303477088.0000\n",
            "Epoch 164/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272136832.0000 - val_loss: 331738656.0000\n",
            "Epoch 165/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272769856.0000 - val_loss: 332533536.0000\n",
            "Epoch 166/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272831232.0000 - val_loss: 349620096.0000\n",
            "Epoch 167/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 282194272.0000 - val_loss: 310194720.0000\n",
            "Epoch 168/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 263941712.0000 - val_loss: 339912576.0000\n",
            "Epoch 169/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 268834272.0000 - val_loss: 311822592.0000\n",
            "Epoch 170/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 272202624.0000 - val_loss: 350464544.0000\n",
            "Epoch 171/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 270522656.0000 - val_loss: 311316608.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "jG1I_-jh7fu0",
        "outputId": "013180c6-b607-43ac-89a9-58170bdf2af6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f78e7aaadd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "prediction = estimator.predict(X_test)\n",
        "print(\"r_square score: \", r2_score(y_test,prediction))\n",
        "#y_test = sc2.inverse_transform(y_test.reshape(-1,1))\n",
        "yy = np.array(y_test)\n",
        "#prediction = sc2.inverse_transform(prediction.reshape(-1,1))\n",
        "predd = np.array(prediction)\n",
        "for i in range(len(yy)):\n",
        "  if(yy[i]-predd[i] > 99000):\n",
        "    print(\"real value of y_test: \" + str(yy[i]) + \" -> the predict: \" + str(predd[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnQXNvh3-rVR",
        "outputId": "693b4b45-dd25-4059-edd0-17476d873471"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 1ms/step\n",
            "r_square score:  0.7897291581237319\n",
            "real value of y_test: 99999.0 -> the predict: 176.85916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "print(\"RMSE:\")\n",
        "sqrt(mean_squared_error(yy, predd)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSyzIFK5uzHP",
        "outputId": "73823246-c9aa-4e63-b6af-8c0876706ed4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16567.29538366403"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}