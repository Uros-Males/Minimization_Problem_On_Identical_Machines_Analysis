{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOn/q7Rg35silAEDfiWgGPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uros-Males/Minimization_Problem_On_Identical_Machines_Analysis/blob/main/NEWNEW_MIXED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "amvyGSys0OkP"
      },
      "outputs": [],
      "source": [
        "#IN PROGRESS....\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import time\n",
        "import keras\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/C-instances-runtime-analysis.csv')\n",
        "\n",
        "\n",
        "\n",
        "df = df[df['n/m']==2]\n",
        "\n",
        "shuffled = df.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = [ 'index', 'inst.name','type', 'CPLEXStatus'] #cple\n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']\n",
        "names = ['indeks', 'n', 'n/m', '(n/m)^2', '(n/m)^3', 'm/n', 'av.length', 'std.dev', 'median', 'range', 'min', 'max', 'k']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_new = []\n",
        "cnt0=0\n",
        "cnt1=0\n",
        "cnt2=0\n",
        "cnt3=0\n",
        "for val in y:\n",
        "  if(val<10):\n",
        "    y_new.append(0)\n",
        "    cnt0+=1\n",
        "  elif(10 <= val and val<1000):\n",
        "    y_new.append(1)\n",
        "    cnt1+=1\n",
        "  else:\n",
        "    y_new.append(2)\n",
        "    cnt2+=1\n",
        "\n",
        "cnt = 0\n",
        "if(cnt0>0):\n",
        "  cnt+=1\n",
        "if(cnt1>0):\n",
        "  cnt+=1\n",
        "if(cnt2>0):\n",
        "  cnt+=1\n",
        "if(cnt3>0):\n",
        "  cnt+=1\n",
        "\n",
        "shuffled['y_new'] = y_new\n",
        "y_encoded = shuffled.loc[:,'y_new']\n",
        "y_new = np.array(y_new)"
      ],
      "metadata": {
        "id": "1jk4i-n54rQB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = [ 'av.length', 'n', 'std.dev', 'k', 'm', 'max']\n",
        "X_modified = X.drop([   'n/m', 'indeks', 'class',  'subtype', '(m/n)^3', '(m/n)^2', '(n/m)^2', '(n/m)^3','m/n','median', 'min', 'range'], axis = 1)\n",
        "print(X_modified.head())\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversample = RandomOverSampler(random_state=0)\n",
        "X_modified, y_encoded = oversample.fit_resample(X_modified, y_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKaCxrM840wN",
        "outputId": "e844513f-e7df-4c20-930d-53827e8f69b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     n    m   av.length     std.dev  max    k             y\n",
            "0  140   70  343.121429  121.472290  556  113     10.026574\n",
            "1   40   20   65.550003   22.500086  100   30      0.920937\n",
            "2  200  100   57.825001   22.578833  100   75     26.029591\n",
            "3  180   90  467.405548  156.015503  717  148      9.815632\n",
            "4  140   70  547.578552  137.977631  917  121  99999.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "l_encode = LabelEncoder()\n",
        "l_encode.fit(y_encoded)\n",
        "y_encoded = l_encode.transform(y_encoded)\n",
        "y_encoded = to_categorical(y_encoded)\n",
        "y_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxf3SgQ_41yz",
        "outputId": "84c726d7-f1a7-4f94-b3bc-e771151edee0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y_encoded, random_state=0, train_size = 0.83)\n",
        "print(X_train.shape[0])\n",
        "print(X_test.shape[0])\n",
        "\n",
        "X_train = X_train.drop(['y', 'k', 'm'], axis = 1)\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test_copy = X_test\n",
        "print(X_test_copy.head())\n",
        "X_test = X_test.drop(['y', 'k', 'm'], axis = 1)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B7m6o_X45DF",
        "outputId": "4740347b-e159-44c8-a03b-9ebdd2c469e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1267\n",
            "260\n",
            "        n    m   av.length     std.dev   max    k             y\n",
            "1362  180   90  706.877808  175.294418  1104  154  99999.000000\n",
            "511   100   50   59.770000   22.366035   100   55      8.042485\n",
            "9     200  100   45.939999   28.773180    98   81      2.639991\n",
            "393    20   10   48.349998   15.812304    79   17      0.146769\n",
            "471    80   40   56.049999   23.062872    99   45      6.669239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(8, input_dim = X_modified.shape[1]-3, activation='relu'))\n",
        "\n",
        "classifier.add(Dense(12, activation = 'relu'))\n",
        "classifier.add(Dropout(0.125))\n",
        "\n",
        "#classifier.add(Dense(32, activation = 'relu'))\n",
        "\n",
        "#classifier.add(Dense(32, activation = 'relu'))\n",
        "#classifier.add(Dense(32, activation = 'relu'))\n",
        "#classifier.add(Dense(16, activation = 'relu'))\n",
        "\n",
        "#classifier.add(Dense(16, activation='relu'))\n",
        "\n",
        "#classifier.add(Dense(8, activation='relu'))\n",
        "\n",
        "#classifier.add(Dense(12, activation='relu'))\n",
        "\n",
        "classifier.add(Dense(cnt, activation = 'softmax'))\n",
        "classifier.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHzkCr_P48Iw",
        "outputId": "d3a93cda-0c00-4ae3-fc72-271449b2f60e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                108       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 39        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 187\n",
            "Trainable params: 187\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 25, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = classifier.fit(X_train, y_train, batch_size = 64, \n",
        "                    epochs = 350, shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HxWFp7_5AoP",
        "outputId": "aad296af-779e-483a-9c68-395df259411d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/350\n",
            "20/20 [==============================] - 1s 4ms/step - loss: 1.1855 - accuracy: 0.3047\n",
            "Epoch 2/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.1332 - accuracy: 0.3481\n",
            "Epoch 3/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 1.0860 - accuracy: 0.4033\n",
            "Epoch 4/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.0528 - accuracy: 0.4586\n",
            "Epoch 5/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.0250 - accuracy: 0.4957\n",
            "Epoch 6/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.9888 - accuracy: 0.5588\n",
            "Epoch 7/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.9698 - accuracy: 0.5462\n",
            "Epoch 8/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.9326 - accuracy: 0.5785\n",
            "Epoch 9/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.9140 - accuracy: 0.5809\n",
            "Epoch 10/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8699 - accuracy: 0.6062\n",
            "Epoch 11/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8470 - accuracy: 0.6069\n",
            "Epoch 12/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8226 - accuracy: 0.6204\n",
            "Epoch 13/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7983 - accuracy: 0.6298\n",
            "Epoch 14/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7780 - accuracy: 0.6764\n",
            "Epoch 15/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7517 - accuracy: 0.6946\n",
            "Epoch 16/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.7258 - accuracy: 0.6922\n",
            "Epoch 17/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.7200 - accuracy: 0.6977\n",
            "Epoch 18/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.7127\n",
            "Epoch 19/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7332\n",
            "Epoch 20/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6459 - accuracy: 0.7372\n",
            "Epoch 21/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6433 - accuracy: 0.7293\n",
            "Epoch 22/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6247 - accuracy: 0.7474\n",
            "Epoch 23/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6055 - accuracy: 0.7522\n",
            "Epoch 24/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5983 - accuracy: 0.7545\n",
            "Epoch 25/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5841 - accuracy: 0.7601\n",
            "Epoch 26/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7609\n",
            "Epoch 27/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.7719\n",
            "Epoch 28/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7766\n",
            "Epoch 29/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.7979\n",
            "Epoch 30/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.7885\n",
            "Epoch 31/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7979\n",
            "Epoch 32/350\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.5127 - accuracy: 0.7979\n",
            "Epoch 33/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7995\n",
            "Epoch 34/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.8153\n",
            "Epoch 35/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.8019\n",
            "Epoch 36/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8122\n",
            "Epoch 37/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.8216\n",
            "Epoch 38/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.8208\n",
            "Epoch 39/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.8319\n",
            "Epoch 40/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.8358\n",
            "Epoch 41/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.8358\n",
            "Epoch 42/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.8335\n",
            "Epoch 43/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.8343\n",
            "Epoch 44/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.8350\n",
            "Epoch 45/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8461\n",
            "Epoch 46/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.8264\n",
            "Epoch 47/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8461\n",
            "Epoch 48/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8516\n",
            "Epoch 49/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.8366\n",
            "Epoch 50/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8611\n",
            "Epoch 51/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8548\n",
            "Epoch 52/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8390\n",
            "Epoch 53/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8508\n",
            "Epoch 54/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8445\n",
            "Epoch 55/350\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.4043 - accuracy: 0.8477\n",
            "Epoch 56/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8477\n",
            "Epoch 57/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8445\n",
            "Epoch 58/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8532\n",
            "Epoch 59/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8477\n",
            "Epoch 60/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4093 - accuracy: 0.8406\n",
            "Epoch 61/350\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.4018 - accuracy: 0.8382\n",
            "Epoch 62/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8556\n",
            "Epoch 63/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8556\n",
            "Epoch 64/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8453\n",
            "Epoch 65/350\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3901 - accuracy: 0.8556\n",
            "Epoch 66/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8516\n",
            "Epoch 67/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3829 - accuracy: 0.8469\n",
            "Epoch 68/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3728 - accuracy: 0.8485\n",
            "Epoch 69/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8579\n",
            "Epoch 70/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8500\n",
            "Epoch 71/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8595\n",
            "Epoch 72/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3845 - accuracy: 0.8493\n",
            "Epoch 73/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8540\n",
            "Epoch 74/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8556\n",
            "Epoch 75/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8532\n",
            "Epoch 76/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8500\n",
            "Epoch 77/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3733 - accuracy: 0.8540\n",
            "Epoch 78/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8642\n",
            "Epoch 79/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8603\n",
            "Epoch 80/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8603\n",
            "Epoch 81/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8500\n",
            "Epoch 82/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8682\n",
            "Epoch 83/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8524\n",
            "Epoch 84/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3591 - accuracy: 0.8532\n",
            "Epoch 85/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3560 - accuracy: 0.8532\n",
            "Epoch 86/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3608 - accuracy: 0.8548\n",
            "Epoch 87/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8587\n",
            "Epoch 88/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3582 - accuracy: 0.8642\n",
            "Epoch 89/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3518 - accuracy: 0.8611\n",
            "Epoch 90/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8548\n",
            "Epoch 91/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3546 - accuracy: 0.8635\n",
            "Epoch 92/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8666\n",
            "Epoch 93/350\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.3454 - accuracy: 0.8658\n",
            "Epoch 94/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8698\n",
            "Epoch 95/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8721\n",
            "Epoch 96/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8737\n",
            "Epoch 97/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3445 - accuracy: 0.8650\n",
            "Epoch 98/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8642\n",
            "Epoch 99/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8650\n",
            "Epoch 100/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8635\n",
            "Epoch 101/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8713\n",
            "Epoch 102/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8627\n",
            "Epoch 103/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3451 - accuracy: 0.8548\n",
            "Epoch 104/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8666\n",
            "Epoch 105/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8682\n",
            "Epoch 106/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3300 - accuracy: 0.8666\n",
            "Epoch 107/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8706\n",
            "Epoch 108/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8642\n",
            "Epoch 109/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8666\n",
            "Epoch 110/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8721\n",
            "Epoch 111/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8785\n",
            "Epoch 112/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.8674\n",
            "Epoch 113/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3169 - accuracy: 0.8824\n",
            "Epoch 114/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3216 - accuracy: 0.8753\n",
            "Epoch 115/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3159 - accuracy: 0.8745\n",
            "Epoch 116/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.8721\n",
            "Epoch 117/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3266 - accuracy: 0.8761\n",
            "Epoch 118/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.8808\n",
            "Epoch 119/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3147 - accuracy: 0.8785\n",
            "Epoch 120/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3053 - accuracy: 0.8808\n",
            "Epoch 121/350\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.3216 - accuracy: 0.8792\n",
            "Epoch 122/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3070 - accuracy: 0.8832\n",
            "Epoch 123/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3126 - accuracy: 0.8871\n",
            "Epoch 124/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8840\n",
            "Epoch 125/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3128 - accuracy: 0.8808\n",
            "Epoch 126/350\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.2998 - accuracy: 0.8848\n",
            "Epoch 127/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.8848\n",
            "Epoch 128/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3026 - accuracy: 0.8871\n",
            "Epoch 129/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2981 - accuracy: 0.8871\n",
            "Epoch 130/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.8927\n",
            "Epoch 131/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8887\n",
            "Epoch 132/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8863\n",
            "Epoch 133/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2945 - accuracy: 0.8887\n",
            "Epoch 134/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2963 - accuracy: 0.8863\n",
            "Epoch 135/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.3022 - accuracy: 0.8871\n",
            "Epoch 136/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2973 - accuracy: 0.8934\n",
            "Epoch 137/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3036 - accuracy: 0.8816\n",
            "Epoch 138/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2926 - accuracy: 0.8879\n",
            "Epoch 139/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8824\n",
            "Epoch 140/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2965 - accuracy: 0.8879\n",
            "Epoch 141/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.8863\n",
            "Epoch 142/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8919\n",
            "Epoch 143/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8887\n",
            "Epoch 144/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.8895\n",
            "Epoch 145/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8887\n",
            "Epoch 146/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2881 - accuracy: 0.8942\n",
            "Epoch 147/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.8887\n",
            "Epoch 148/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.8950\n",
            "Epoch 149/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8990\n",
            "Epoch 150/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8966\n",
            "Epoch 151/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2892 - accuracy: 0.8927\n",
            "Epoch 152/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8958\n",
            "Epoch 153/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2788 - accuracy: 0.8998\n",
            "Epoch 154/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2879 - accuracy: 0.8950\n",
            "Epoch 155/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.8919\n",
            "Epoch 156/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.8958\n",
            "Epoch 157/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2760 - accuracy: 0.8958\n",
            "Epoch 158/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2880 - accuracy: 0.8911\n",
            "Epoch 159/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2824 - accuracy: 0.8974\n",
            "Epoch 160/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2801 - accuracy: 0.9029\n",
            "Epoch 161/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.8950\n",
            "Epoch 162/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2714 - accuracy: 0.9029\n",
            "Epoch 163/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2845 - accuracy: 0.8990\n",
            "Epoch 164/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8982\n",
            "Epoch 165/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8974\n",
            "Epoch 166/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.8942\n",
            "Epoch 167/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.9006\n",
            "Epoch 168/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2713 - accuracy: 0.9037\n",
            "Epoch 169/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2801 - accuracy: 0.8887\n",
            "Epoch 170/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2748 - accuracy: 0.8934\n",
            "Epoch 171/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2631 - accuracy: 0.9069\n",
            "Epoch 172/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2725 - accuracy: 0.8974\n",
            "Epoch 173/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2635 - accuracy: 0.9029\n",
            "Epoch 174/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.8982\n",
            "Epoch 175/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.8950\n",
            "Epoch 176/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.9021\n",
            "Epoch 177/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2682 - accuracy: 0.9053\n",
            "Epoch 178/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2635 - accuracy: 0.9013\n",
            "Epoch 179/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2672 - accuracy: 0.9053\n",
            "Epoch 180/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2546 - accuracy: 0.9092\n",
            "Epoch 181/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2649 - accuracy: 0.9037\n",
            "Epoch 182/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2655 - accuracy: 0.8990\n",
            "Epoch 183/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2624 - accuracy: 0.9053\n",
            "Epoch 184/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.9029\n",
            "Epoch 185/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.9084\n",
            "Epoch 186/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.9029\n",
            "Epoch 187/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2633 - accuracy: 0.9029\n",
            "Epoch 188/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2644 - accuracy: 0.9037\n",
            "Epoch 189/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.8990\n",
            "Epoch 190/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2617 - accuracy: 0.8982\n",
            "Epoch 191/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2608 - accuracy: 0.9100\n",
            "Epoch 192/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.9092\n",
            "Epoch 193/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.9013\n",
            "Epoch 194/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2609 - accuracy: 0.9045\n",
            "Epoch 195/350\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2530 - accuracy: 0.9108\n",
            "Epoch 196/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2556 - accuracy: 0.9077\n",
            "Epoch 197/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2540 - accuracy: 0.9037\n",
            "Epoch 198/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2592 - accuracy: 0.8998\n",
            "Epoch 199/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2510 - accuracy: 0.8998\n",
            "Epoch 200/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2615 - accuracy: 0.8942\n",
            "Epoch 201/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.9084\n",
            "Epoch 202/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.9029\n",
            "Epoch 203/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2520 - accuracy: 0.9077\n",
            "Epoch 204/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2526 - accuracy: 0.9069\n",
            "Epoch 205/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2626 - accuracy: 0.8974\n",
            "Epoch 206/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2519 - accuracy: 0.9069\n",
            "Epoch 207/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.9013\n",
            "Epoch 208/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2613 - accuracy: 0.8958\n",
            "Epoch 209/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2437 - accuracy: 0.9116\n",
            "Epoch 210/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.9148\n",
            "Epoch 211/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2429 - accuracy: 0.9077\n",
            "Epoch 212/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.9053\n",
            "Epoch 213/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2537 - accuracy: 0.8966\n",
            "Epoch 214/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.9061\n",
            "Epoch 215/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.9037\n",
            "Epoch 216/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9006\n",
            "Epoch 217/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2504 - accuracy: 0.9077\n",
            "Epoch 218/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2440 - accuracy: 0.9053\n",
            "Epoch 219/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2458 - accuracy: 0.9077\n",
            "Epoch 220/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2433 - accuracy: 0.9061\n",
            "Epoch 221/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2435 - accuracy: 0.9053\n",
            "Epoch 222/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.9155\n",
            "Epoch 223/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2415 - accuracy: 0.9084\n",
            "Epoch 224/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.9061\n",
            "Epoch 225/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.9116\n",
            "Epoch 226/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.9116\n",
            "Epoch 227/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.9045\n",
            "Epoch 228/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2415 - accuracy: 0.9084\n",
            "Epoch 229/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.9069\n",
            "Epoch 230/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2404 - accuracy: 0.9124\n",
            "Epoch 231/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2386 - accuracy: 0.9124\n",
            "Epoch 232/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9029\n",
            "Epoch 233/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.9108\n",
            "Epoch 234/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.9124\n",
            "Epoch 235/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.9021\n",
            "Epoch 236/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.9053\n",
            "Epoch 237/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2325 - accuracy: 0.9148\n",
            "Epoch 238/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2248 - accuracy: 0.9155\n",
            "Epoch 239/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.9124\n",
            "Epoch 240/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2378 - accuracy: 0.9132\n",
            "Epoch 241/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2353 - accuracy: 0.9053\n",
            "Epoch 242/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2282 - accuracy: 0.9108\n",
            "Epoch 243/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.9108\n",
            "Epoch 244/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2374 - accuracy: 0.9084\n",
            "Epoch 245/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.9100\n",
            "Epoch 246/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.9029\n",
            "Epoch 247/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2370 - accuracy: 0.9053\n",
            "Epoch 248/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2381 - accuracy: 0.9124\n",
            "Epoch 249/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2347 - accuracy: 0.9203\n",
            "Epoch 250/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.9155\n",
            "Epoch 251/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.9132\n",
            "Epoch 252/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2327 - accuracy: 0.9092\n",
            "Epoch 253/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.9116\n",
            "Epoch 254/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9148\n",
            "Epoch 255/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.9069\n",
            "Epoch 256/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2306 - accuracy: 0.9100\n",
            "Epoch 257/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.9211\n",
            "Epoch 258/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2281 - accuracy: 0.9092\n",
            "Epoch 259/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2246 - accuracy: 0.9148\n",
            "Epoch 260/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2319 - accuracy: 0.9179\n",
            "Epoch 261/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2233 - accuracy: 0.9179\n",
            "Epoch 262/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2251 - accuracy: 0.9148\n",
            "Epoch 263/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2192 - accuracy: 0.9242\n",
            "Epoch 264/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2315 - accuracy: 0.9163\n",
            "Epoch 265/350\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.2347 - accuracy: 0.9124\n",
            "Epoch 266/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2251 - accuracy: 0.9092\n",
            "Epoch 267/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9124\n",
            "Epoch 268/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2389 - accuracy: 0.9053\n",
            "Epoch 269/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2238 - accuracy: 0.9195\n",
            "Epoch 270/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2237 - accuracy: 0.9163\n",
            "Epoch 271/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2370 - accuracy: 0.9084\n",
            "Epoch 272/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2426 - accuracy: 0.9100\n",
            "Epoch 273/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2268 - accuracy: 0.9227\n",
            "Epoch 274/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.9108\n",
            "Epoch 275/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2225 - accuracy: 0.9227\n",
            "Epoch 276/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2302 - accuracy: 0.9163\n",
            "Epoch 277/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2389 - accuracy: 0.9037\n",
            "Epoch 278/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2218 - accuracy: 0.9092\n",
            "Epoch 279/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2267 - accuracy: 0.9171\n",
            "Epoch 280/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9155\n",
            "Epoch 281/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2195 - accuracy: 0.9234\n",
            "Epoch 282/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.9163\n",
            "Epoch 283/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9077\n",
            "Epoch 284/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2245 - accuracy: 0.9148\n",
            "Epoch 285/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2308 - accuracy: 0.9077\n",
            "Epoch 286/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.9148\n",
            "Epoch 287/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2282 - accuracy: 0.9132\n",
            "Epoch 288/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2272 - accuracy: 0.9163\n",
            "Epoch 289/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.9187\n",
            "Epoch 290/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2250 - accuracy: 0.9163\n",
            "Epoch 291/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2264 - accuracy: 0.9124\n",
            "Epoch 292/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2179 - accuracy: 0.9148\n",
            "Epoch 293/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2215 - accuracy: 0.9195\n",
            "Epoch 294/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9179\n",
            "Epoch 295/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9132\n",
            "Epoch 296/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9171\n",
            "Epoch 297/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2296 - accuracy: 0.9116\n",
            "Epoch 298/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9211\n",
            "Epoch 299/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2123 - accuracy: 0.9203\n",
            "Epoch 300/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2186 - accuracy: 0.9163\n",
            "Epoch 301/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2167 - accuracy: 0.9242\n",
            "Epoch 302/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2196 - accuracy: 0.9140\n",
            "Epoch 303/350\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2163 - accuracy: 0.9163\n",
            "Epoch 304/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.9211\n",
            "Epoch 305/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2216 - accuracy: 0.9163\n",
            "Epoch 306/350\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.2286 - accuracy: 0.9108\n",
            "Epoch 307/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2316 - accuracy: 0.9148\n",
            "Epoch 308/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9195\n",
            "Epoch 309/350\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2193 - accuracy: 0.9155\n",
            "Epoch 310/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2095 - accuracy: 0.9179\n",
            "Epoch 311/350\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.2160 - accuracy: 0.9179\n",
            "Epoch 312/350\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9132\n",
            "Epoch 313/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2171 - accuracy: 0.9179\n",
            "Epoch 314/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2323 - accuracy: 0.9100\n",
            "Epoch 315/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2174 - accuracy: 0.9171\n",
            "Epoch 316/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9211\n",
            "Epoch 317/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9077\n",
            "Epoch 318/350\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.2154 - accuracy: 0.9179\n",
            "Epoch 319/350\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9211\n",
            "Epoch 320/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.9148\n",
            "Epoch 321/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9187\n",
            "Epoch 322/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2063 - accuracy: 0.9258\n",
            "Epoch 323/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.9148\n",
            "Epoch 324/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2105 - accuracy: 0.9282\n",
            "Epoch 325/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.9258\n",
            "Epoch 326/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9140\n",
            "Epoch 327/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9148\n",
            "Epoch 328/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9250\n",
            "Epoch 329/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.9140\n",
            "Epoch 330/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9203\n",
            "Epoch 331/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9242\n",
            "Epoch 332/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.9227\n",
            "Epoch 333/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9171\n",
            "Epoch 334/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.9077\n",
            "Epoch 335/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.9171\n",
            "Epoch 336/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9116\n",
            "Epoch 337/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2074 - accuracy: 0.9227\n",
            "Epoch 338/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9163\n",
            "Epoch 339/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9155\n",
            "Epoch 340/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9187\n",
            "Epoch 341/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.9179\n",
            "Epoch 342/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9227\n",
            "Epoch 343/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2107 - accuracy: 0.9211\n",
            "Epoch 344/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9171\n",
            "Epoch 345/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9227\n",
            "Epoch 346/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9203\n",
            "Epoch 347/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9155\n",
            "Epoch 348/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2078 - accuracy: 0.9179\n",
            "Epoch 349/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9179\n",
            "Epoch 350/350\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.9195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import accuracy\n",
        "pred = classifier.predict(X_test)\n",
        "pred_ = np.argmax(pred, axis = 1)\n",
        "pred_ = l_encode.inverse_transform(pred_)\n",
        "\n",
        "true_y = l_encode.inverse_transform(np.argmax(to_categorical(y_test), axis = 1)[:,1])\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(true_y, pred_, labels=[0, 1, 2])\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=['easy','moderate/hard', 'very hard'])\n",
        "cmd.plot()\n",
        "\n",
        "cnt = 0\n",
        "cnt_correct = 0\n",
        "for i in range(len(pred)):\n",
        "  cnt += 1\n",
        "  if(pred_[i] == true_y[i]):\n",
        "    cnt_correct += 1\n",
        "print(f'accuracy: {(cnt_correct/cnt)*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "uddqepBt5EkP",
        "outputId": "8b7841e4-3ee0-4df0-ae6c-e404e238feb9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 93.08%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['n', 'k', 'n/m', 'av.length', 'std.dev', 'y']\n",
        "df_reg = pd.DataFrame(columns = column_names)\n",
        "print(X_test_copy.shape[0])\n",
        "print(len(pred))\n",
        "for i in range(len(pred)):\n",
        "  if(pred_[i] == 1):\n",
        "    dictionary = {'n' : X_test_copy.iloc[i]['n'], 'n/m': 2, \n",
        "                  'av.length' : X_test_copy.iloc[i]['av.length'], 'std.dev' : X_test_copy.iloc[i]['std.dev'],\n",
        "                  'k' : X_test_copy.iloc[i]['k'], 'y': X_test_copy.iloc[i]['y']}\n",
        "    df_reg = df_reg.append(dictionary, ignore_index = True)\n",
        "#VM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIbvATDjCLTq",
        "outputId": "a6832444-1218-4450-de7b-e5696108163c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260\n",
            "260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['n', 'k', 'm', 'std.dev', 'y']\n",
        "df_reg0 = pd.DataFrame(columns = column_names)\n",
        "print(X_test_copy.shape[0])\n",
        "print(len(pred))\n",
        "for i in range(len(pred)):\n",
        "  if(pred_[i] == 0):\n",
        "    dictionary = {'n' : X_test_copy.iloc[i]['n'], \n",
        "                  'm' : X_test_copy.iloc[i]['m'], 'std.dev' : X_test_copy.iloc[i]['std.dev'],\n",
        "                  'k' : X_test_copy.iloc[i]['k'], 'y': X_test_copy.iloc[i]['y']}\n",
        "    df_reg0 = df_reg0.append(dictionary, ignore_index = True)\n",
        "#EASY"
      ],
      "metadata": {
        "id": "9tqrtKj1VBkA",
        "outputId": "0f8c6da0-0556-471d-a6cd-d7503d76d5ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260\n",
            "260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['n', 'k', 'av.length', 'std.dev', 'y']\n",
        "df_reg2 = pd.DataFrame(columns = column_names)\n",
        "print(X_test_copy.shape[0])\n",
        "print(len(pred))\n",
        "for i in range(len(pred)):\n",
        "  if(pred_[i] == 2):\n",
        "    dictionary = {'n' : X_test_copy.iloc[i]['n'], \n",
        "                  'av.length' : X_test_copy.iloc[i]['av.length'], 'std.dev' : X_test_copy.iloc[i]['std.dev'],\n",
        "                  'k' : X_test_copy.iloc[i]['k'], 'y': X_test_copy.iloc[i]['y']}\n",
        "    df_reg2 = df_reg2.append(dictionary, ignore_index = True)\n",
        "\n",
        "#VHARD"
      ],
      "metadata": {
        "id": "SIEyHIVPVvyU",
        "outputId": "c26e4783-a930-4706-87dc-81ceb98eac5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "260\n",
            "260\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IN PROGRESS....\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import time\n",
        "import keras\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/C-instances-runtime-analysis.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = df[df['n/m']!=2]\n",
        "\n",
        "shuffled = df.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = [ 'index', 'inst.name','type', 'CPLEXStatus'] \n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']\n",
        "names = ['indeks', 'n', 'n/m', '(n/m)^2', '(n/m)^3', 'm/n', 'av.length', 'std.dev', 'median', 'range', 'min', 'max', 'k']"
      ],
      "metadata": {
        "id": "P9a6vACH7zLA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_new = []\n",
        "for val in y:\n",
        "  if(val<10):\n",
        "    y_new.append(0)\n",
        "  elif(10 <= val and val <1000):\n",
        "    y_new.append(1)\n",
        "  else:\n",
        "    y_new.append(2)\n",
        "\n",
        "shuffled['y_new'] = y_new\n",
        "y_encoded = shuffled.loc[:,'y_new']\n",
        "y_new = np.array(y_new)\n",
        "X_modified = X"
      ],
      "metadata": {
        "id": "Mt9OHP2u9xhR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "names =[ 'std.dev', 'n','n/m', 'max','av.length', 'm', 'k']\n",
        "X_modified = X.drop([  'median', 'range',  'min','indeks', 'class',  'subtype', '(m/n)^3', '(m/n)^2', '(n/m)^2', '(n/m)^3','m/n'], axis = 1)\n",
        "X_modified['n/m'] = X_modified['n/m']\n",
        "#print(X_modified.head())\n",
        "\n",
        "oversample = RandomOverSampler(random_state=0)\n",
        "#oversample.fit(X_modified, y_encoded)\n",
        "X_modified, y_encoded = oversample.fit_resample(X_modified, y_encoded)"
      ],
      "metadata": {
        "id": "IGD1S2VI91L8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "l_encode = LabelEncoder()\n",
        "l_encode.fit(y_encoded)\n",
        "y_encoded = l_encode.transform(y_encoded)\n",
        "y_encoded = to_categorical(y_encoded)\n",
        "y_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdnbu1X494sV",
        "outputId": "ab062978-c1e8-4068-e217-a9a2fc2e7237"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y_encoded, random_state=0, train_size = 0.83)\n",
        "print(X_train.shape[0])\n",
        "print(X_test.shape[0])\n",
        "\n",
        "X_train = X_train.drop(['y', 'n', 'm', 'std.dev'], axis = 1)\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test_copy = X_test\n",
        "print(X_test_copy.head())\n",
        "X_test = X_test.drop(['y', 'n', 'm', 'std.dev'], axis = 1)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlUE_owL98c2",
        "outputId": "ee1ddeca-463d-48d1-c45b-7cb0d59f66b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11401\n",
            "2336\n",
            "         n   m    n/m   av.length     std.dev   max    k             y\n",
            "3234    40  16   2.50   99.150002   32.385933   160   35      5.184934\n",
            "4495   180  60   3.00  449.022217  154.397949   714  150    526.371094\n",
            "10982   18   8   2.25  106.500000   55.454536   206   18      0.221920\n",
            "9657    80  32   2.50   60.450001   25.334669   100   53      9.711271\n",
            "5976   154  14  11.00  609.844177  150.485596  1017  135  99999.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(16, input_dim = X_modified.shape[1]-4, activation='relu'))\n",
        "\n",
        "classifier.add(Dropout(0.2))\n",
        "\n",
        "classifier.add(Dense(3, activation = 'softmax'))\n",
        "classifier.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvhqjpBH9_u0",
        "outputId": "c2bc3e12-3319-4e9c-9476-3c37ba4ee8cd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 16)                80        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 25, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = classifier.fit(X_train, y_train, batch_size = 32, \n",
        "                    epochs = 120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh4s76I9-FP2",
        "outputId": "c2767eaa-bfd2-4a0b-f90d-c03f72588e1a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.6989 - accuracy: 0.7091\n",
            "Epoch 2/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.8079\n",
            "Epoch 3/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.4350 - accuracy: 0.8292\n",
            "Epoch 4/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.4084 - accuracy: 0.8366\n",
            "Epoch 5/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3958 - accuracy: 0.8440\n",
            "Epoch 6/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3819 - accuracy: 0.8498\n",
            "Epoch 7/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3754 - accuracy: 0.8536\n",
            "Epoch 8/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3664 - accuracy: 0.8534\n",
            "Epoch 9/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8560\n",
            "Epoch 10/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3604 - accuracy: 0.8589\n",
            "Epoch 11/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3530 - accuracy: 0.8595\n",
            "Epoch 12/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8612\n",
            "Epoch 13/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3467 - accuracy: 0.8621\n",
            "Epoch 14/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.8634\n",
            "Epoch 15/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8648\n",
            "Epoch 16/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.8657\n",
            "Epoch 17/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8670\n",
            "Epoch 18/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8676\n",
            "Epoch 19/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8677\n",
            "Epoch 20/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8676\n",
            "Epoch 21/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8636\n",
            "Epoch 22/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8684\n",
            "Epoch 23/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8708\n",
            "Epoch 24/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8718\n",
            "Epoch 25/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3204 - accuracy: 0.8681\n",
            "Epoch 26/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.8685\n",
            "Epoch 27/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8719\n",
            "Epoch 28/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3145 - accuracy: 0.8705\n",
            "Epoch 29/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8686\n",
            "Epoch 30/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.8742\n",
            "Epoch 31/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3089 - accuracy: 0.8712\n",
            "Epoch 32/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3159 - accuracy: 0.8753\n",
            "Epoch 33/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3142 - accuracy: 0.8741\n",
            "Epoch 34/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8737\n",
            "Epoch 35/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3114 - accuracy: 0.8758\n",
            "Epoch 36/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3115 - accuracy: 0.8752\n",
            "Epoch 37/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3062 - accuracy: 0.8734\n",
            "Epoch 38/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3074 - accuracy: 0.8755\n",
            "Epoch 39/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3044 - accuracy: 0.8765\n",
            "Epoch 40/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3146 - accuracy: 0.8695\n",
            "Epoch 41/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3031 - accuracy: 0.8738\n",
            "Epoch 42/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3091 - accuracy: 0.8730\n",
            "Epoch 43/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3093 - accuracy: 0.8725\n",
            "Epoch 44/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3062 - accuracy: 0.8769\n",
            "Epoch 45/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3064 - accuracy: 0.8763\n",
            "Epoch 46/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3007 - accuracy: 0.8762\n",
            "Epoch 47/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3069 - accuracy: 0.8745\n",
            "Epoch 48/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3073 - accuracy: 0.8740\n",
            "Epoch 49/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3043 - accuracy: 0.8774\n",
            "Epoch 50/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3052 - accuracy: 0.8772\n",
            "Epoch 51/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3040 - accuracy: 0.8768\n",
            "Epoch 52/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3054 - accuracy: 0.8755\n",
            "Epoch 53/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8774\n",
            "Epoch 54/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8777\n",
            "Epoch 55/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2994 - accuracy: 0.8771\n",
            "Epoch 56/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3038 - accuracy: 0.8776\n",
            "Epoch 57/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3028 - accuracy: 0.8754\n",
            "Epoch 58/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2992 - accuracy: 0.8775\n",
            "Epoch 59/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3057 - accuracy: 0.8735\n",
            "Epoch 60/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3020 - accuracy: 0.8762\n",
            "Epoch 61/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3031 - accuracy: 0.8743\n",
            "Epoch 62/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3002 - accuracy: 0.8783\n",
            "Epoch 63/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3005 - accuracy: 0.8784\n",
            "Epoch 64/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2974 - accuracy: 0.8790\n",
            "Epoch 65/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2983 - accuracy: 0.8783\n",
            "Epoch 66/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2987 - accuracy: 0.8793\n",
            "Epoch 67/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3024 - accuracy: 0.8785\n",
            "Epoch 68/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2972 - accuracy: 0.8794\n",
            "Epoch 69/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.8796\n",
            "Epoch 70/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3000 - accuracy: 0.8800\n",
            "Epoch 71/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2959 - accuracy: 0.8812\n",
            "Epoch 72/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.8805\n",
            "Epoch 73/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2943 - accuracy: 0.8842\n",
            "Epoch 74/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2969 - accuracy: 0.8830\n",
            "Epoch 75/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.8802\n",
            "Epoch 76/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3003 - accuracy: 0.8765\n",
            "Epoch 77/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.3010 - accuracy: 0.8774\n",
            "Epoch 78/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2962 - accuracy: 0.8781\n",
            "Epoch 79/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2928 - accuracy: 0.8805\n",
            "Epoch 80/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2976 - accuracy: 0.8799\n",
            "Epoch 81/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2954 - accuracy: 0.8824\n",
            "Epoch 82/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2963 - accuracy: 0.8801\n",
            "Epoch 83/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2935 - accuracy: 0.8800\n",
            "Epoch 84/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2934 - accuracy: 0.8804\n",
            "Epoch 85/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2935 - accuracy: 0.8790\n",
            "Epoch 86/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2925 - accuracy: 0.8810\n",
            "Epoch 87/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8793\n",
            "Epoch 88/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2909 - accuracy: 0.8817\n",
            "Epoch 89/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2900 - accuracy: 0.8812\n",
            "Epoch 90/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2930 - accuracy: 0.8790\n",
            "Epoch 91/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2934 - accuracy: 0.8797\n",
            "Epoch 92/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2908 - accuracy: 0.8771\n",
            "Epoch 93/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2917 - accuracy: 0.8795\n",
            "Epoch 94/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8808\n",
            "Epoch 95/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2895 - accuracy: 0.8843\n",
            "Epoch 96/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2900 - accuracy: 0.8798\n",
            "Epoch 97/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2935 - accuracy: 0.8790\n",
            "Epoch 98/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2929 - accuracy: 0.8825\n",
            "Epoch 99/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2932 - accuracy: 0.8807\n",
            "Epoch 100/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2920 - accuracy: 0.8820\n",
            "Epoch 101/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.8821\n",
            "Epoch 102/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2900 - accuracy: 0.8845\n",
            "Epoch 103/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2923 - accuracy: 0.8789\n",
            "Epoch 104/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2890 - accuracy: 0.8813\n",
            "Epoch 105/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2906 - accuracy: 0.8812\n",
            "Epoch 106/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2927 - accuracy: 0.8805\n",
            "Epoch 107/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8809\n",
            "Epoch 108/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2930 - accuracy: 0.8797\n",
            "Epoch 109/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2903 - accuracy: 0.8806\n",
            "Epoch 110/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8822\n",
            "Epoch 111/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8824\n",
            "Epoch 112/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2883 - accuracy: 0.8839\n",
            "Epoch 113/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2886 - accuracy: 0.8797\n",
            "Epoch 114/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2883 - accuracy: 0.8854\n",
            "Epoch 115/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.8847\n",
            "Epoch 116/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2843 - accuracy: 0.8856\n",
            "Epoch 117/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8840\n",
            "Epoch 118/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2893 - accuracy: 0.8829\n",
            "Epoch 119/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2898 - accuracy: 0.8812\n",
            "Epoch 120/120\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import accuracy\n",
        "pred = classifier.predict(X_test)\n",
        "pred_ = np.argmax(pred, axis = 1)\n",
        "pred_ = l_encode.inverse_transform(pred_)\n",
        "\n",
        "true_y = l_encode.inverse_transform(np.argmax(to_categorical(y_test), axis = 1)[:,1])\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(true_y, pred_, labels=[0, 1, 2])\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=['easy','moderate/hard', 'very hard'])\n",
        "\n",
        "cmd.plot()\n",
        "\n",
        "cnt = 0\n",
        "cnt_correct = 0\n",
        "for i in range(len(pred)):\n",
        "  cnt += 1\n",
        "  if(pred_[i] == true_y[i]):\n",
        "    cnt_correct += 1\n",
        "print(f'accuracy: {(cnt_correct/cnt)*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "RYneViFj-F05",
        "outputId": "b0e4c772-bc8a-433f-ccd9-f6a8906724d9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 88.53%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred)):\n",
        "  if(pred_[i] == 1):\n",
        "    dictionary = {'n' : X_test_copy.iloc[i]['n'], 'n/m': X_test_copy.iloc[i]['n/m'], \n",
        "                  'av.length' : X_test_copy.iloc[i]['av.length'], 'std.dev' : X_test_copy.iloc[i]['std.dev'],\n",
        "                  'k' : X_test_copy.iloc[i]['k'], 'y': X_test_copy.iloc[i]['y']}\n",
        "    df_reg = df_reg.append(dictionary, ignore_index = True)\n",
        "\n",
        "for i in range(len(pred)):\n",
        "  if(pred_[i] == 0):\n",
        "    dictionary = {'n' : X_test_copy.iloc[i]['n'], \n",
        "                  'm' : X_test_copy.iloc[i]['m'], 'std.dev' : X_test_copy.iloc[i]['std.dev'],\n",
        "                  'k' : X_test_copy.iloc[i]['k'], 'y': X_test_copy.iloc[i]['y']}\n",
        "    df_reg0 = df_reg0.append(dictionary, ignore_index = True)\n",
        "#EASY\n",
        "\n",
        "for i in range(len(pred)):\n",
        "  if(pred_[i] == 2):\n",
        "    dictionary = {'n' : X_test_copy.iloc[i]['n'], \n",
        "                  'av.length' : X_test_copy.iloc[i]['av.length'], 'std.dev' : X_test_copy.iloc[i]['std.dev'],\n",
        "                  'k' : X_test_copy.iloc[i]['k'], 'y': X_test_copy.iloc[i]['y']}\n",
        "    df_reg2 = df_reg2.append(dictionary, ignore_index = True)\n",
        "\n",
        "#VHARD"
      ],
      "metadata": {
        "id": "Gbdkp-4CAIgr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_reg.shape[0])\n",
        "print(df_reg.head(500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvWFrDKjDsB2",
        "outputId": "e9d0f174-a3fe-4635-e909-7506b21858a2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "810\n",
            "         n      k   n/m   av.length     std.dev          y\n",
            "0    200.0   81.0  2.00   45.939999   28.773180   2.639991\n",
            "1    120.0   68.0  2.00   59.224998   22.930464  11.224472\n",
            "2    180.0   48.0  2.00   75.883331   15.566857  14.036451\n",
            "3    140.0  119.0  2.00  332.799988  112.981964  31.155790\n",
            "4    140.0  118.0  2.00  336.092865  112.169182  26.046606\n",
            "..     ...    ...   ...         ...         ...        ...\n",
            "495  176.0   86.0  2.75   48.477272   29.473080  37.967934\n",
            "496  180.0   72.0  5.00   58.505554   23.007040  66.508308\n",
            "497   54.0   46.0  4.50  134.166672   44.849751  48.309464\n",
            "498  140.0   50.0  2.50   73.442856   14.530680  19.191570\n",
            "499  126.0   68.0  3.00   61.674603   22.464844  28.213385\n",
            "\n",
            "[500 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_reg0.head())"
      ],
      "metadata": {
        "id": "zmTqU4gCd7qy",
        "outputId": "0c4e23db-2f94-48de-fce6-148f1db3cdd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       n     k     m     std.dev         y\n",
            "0  100.0  55.0  50.0   22.366035  8.042485\n",
            "1   20.0  17.0  10.0   15.812304  0.146769\n",
            "2   80.0  45.0  40.0   23.062872  6.669239\n",
            "3  100.0  87.0  50.0  102.894897  3.314548\n",
            "4   40.0  34.0  20.0   38.792603  1.172840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_reg2.head())"
      ],
      "metadata": {
        "id": "OY4fn082d-OD",
        "outputId": "55b62094-f79b-4bf4-a843-0807c0c5550b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       n      k   av.length     std.dev             y\n",
            "0  180.0  154.0  706.877808  175.294418  99999.000000\n",
            "1  120.0  101.0  467.700012  115.940849  99999.000000\n",
            "2   80.0   57.0   99.199997   47.029049  99999.000000\n",
            "3   80.0   66.0  106.937500   48.509495  99999.000000\n",
            "4  120.0   89.0  101.000000   46.163391      0.703672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(df_reg.shape[0]):\n",
        "  if(df_reg.iloc[i]['y'] >1000):\n",
        "    df_reg.loc[i, 'y'] = 1001\n",
        "\n",
        "for i in range(df_reg0.shape[0]):\n",
        "  if(df_reg0.iloc[i]['y'] > 10):\n",
        "    df_reg0.loc[i, 'y'] = 11\n",
        "\n",
        "for i in range(df_reg2.shape[0]):\n",
        "  if(df_reg2.iloc[i]['y'] == 99999):\n",
        "    df_reg2.loc[i, 'y'] = 4510\n",
        "\n",
        "\n",
        "print(df_reg['y'].max())\n",
        "shuffled = df_reg.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = ['y', 'index', 'inst.name','type', 'CPLEXStatus']\n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']\n",
        "X_modified = X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STxF3c_kMGtp",
        "outputId": "6ce0b993-eb72-4782-8a60-a9463ba711f5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1001.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "oversample = RandomOverSampler(random_state=0)\n",
        "X_modified, y = oversample.fit_resample(X_modified, y.astype('int'))\n",
        "print(X_modified.shape[0])\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote_on_3 = 50\n",
        "#oversample = SMOTE(sampling_strategy={99999:50000})\n",
        "#X_modified, y = oversample.fit_resample(X_modified, y)\n",
        "print(X_modified.shape[0])\n",
        "\n",
        "tmp = X_modified\n",
        "tmp['y'] = y\n",
        "tmp = tmp.sample(frac = 1).reset_index()\n",
        "print(tmp.head(60))\n",
        "#y = np.log10(tmp['y']*10)+20\n",
        "y = tmp['y']\n",
        "X_modified = tmp.drop(['y'], axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbZsImk5MaVQ",
        "outputId": "fa00571c-8c5c-488a-ece1-ca0772256a1f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7904\n",
            "7904\n",
            "    index      n      k    n/m   av.length     std.dev    y\n",
            "0    6210  162.0   71.0   4.50   97.962959   21.328800  324\n",
            "1    4064   44.0   38.0  11.00   53.590908   29.511780  127\n",
            "2    5201  160.0   70.0   5.00   99.443748   19.852201  194\n",
            "3    6469  126.0   62.0   6.00   62.365078   22.095287  373\n",
            "4    2525  180.0   73.0   2.50   98.894447   20.039488   71\n",
            "5    1015  176.0  109.0   2.75  102.232956   48.726254    9\n",
            "6     886  180.0  119.0   2.00   97.027779   45.132622    3\n",
            "7    4897  180.0   72.0   4.50   99.150002   19.391722  178\n",
            "8    3903   44.0   28.0  11.00   76.954544   15.064134  121\n",
            "9    7373  140.0  123.0   2.50  342.857147  124.946678  548\n",
            "10    751  200.0  119.0   2.50  101.699997   49.112724    4\n",
            "11   3982   54.0   51.0   4.50  136.425919   47.734165  124\n",
            "12    998  108.0   46.0   2.25   75.685188   14.298976    8\n",
            "13   6423  162.0  113.0   4.50  100.049385   52.371666  360\n",
            "14   7824  140.0   97.0   5.00   99.942856   45.319302  750\n",
            "15    597   72.0   63.0   6.00  106.555557   51.322475   34\n",
            "16   6102   60.0   53.0   4.00  243.283340   60.738979  314\n",
            "17   6428  162.0  113.0   4.50  100.049385   52.371666  360\n",
            "18   2250  126.0   74.0   6.00   54.103176   28.623859   60\n",
            "19   2726  100.0   46.0   4.00   74.820000   14.846271   78\n",
            "20   3694   44.0   30.0  11.00   72.386360   14.793487  115\n",
            "21   4840   80.0   71.0   4.00  109.387497   53.714314  174\n",
            "22   2118  198.0   80.0   3.00   99.742424   21.869926   55\n",
            "23   2159  180.0   72.0   3.00   99.150002   19.391722   56\n",
            "24   4454  162.0  108.0   4.50  104.382713   49.349834  144\n",
            "25   6701  120.0   83.0   4.00   98.966667   46.259216  402\n",
            "26   2234  126.0   65.0   3.00  100.238098   20.078020   59\n",
            "27   5196  160.0   70.0   5.00   99.443748   19.852201  194\n",
            "28   3051  198.0   51.0   2.75   74.782829   15.010939   89\n",
            "29   7162  126.0   86.0   4.50  103.968254   41.774616  495\n",
            "30   1062  180.0   82.0   2.00   49.311111   29.608297   11\n",
            "31   7642  140.0   95.0   5.00  112.371429   43.353874  684\n",
            "32   4624   90.0   73.0   4.50  224.044449   77.148468  156\n",
            "33   4420   72.0   59.0   4.50  184.736115   66.265999  143\n",
            "34   5161   72.0   60.0   6.00  171.791672   63.364120  193\n",
            "35   5665  100.0   83.0   4.00   98.300003   50.605125  248\n",
            "36   3745  200.0   75.0   2.50  100.500000   20.163900  116\n",
            "37   4519   88.0   80.0   2.75  369.102264   87.106621  152\n",
            "38   2210  200.0  121.0   2.50   99.455002   48.254864   58\n",
            "39   7134  108.0   81.0   4.50  101.666664   47.730545  494\n",
            "40   5601  144.0   98.0   3.00   99.215279   44.650650  244\n",
            "41   7285  200.0   50.0   5.00   75.175003   15.727400  529\n",
            "42   6830  162.0   71.0   6.00   57.469135   24.604242  437\n",
            "43   1747  126.0   47.0   4.50   76.087303   14.434969   41\n",
            "44    236  198.0  110.0   3.00   95.585861   44.034363  107\n",
            "45   3222  126.0   71.0   4.50   49.515873   27.777327   96\n",
            "46   7518  126.0  107.0   3.00  320.476196  111.572891  644\n",
            "47   4921  108.0   80.0   3.00   97.962959   46.591270  179\n",
            "48   6048  160.0  100.0   4.00  102.606247   46.929787  309\n",
            "49   2958  110.0   80.0   2.75   99.336365   45.512432   86\n",
            "50   5019  198.0   77.0   2.75   99.601013   20.879333  183\n",
            "51   4898  180.0   72.0   4.50   99.150002   19.391722  178\n",
            "52    705  140.0   74.0   2.00   50.671429   27.341806   12\n",
            "53   6576  144.0  101.0   4.50   96.645836   45.839096  382\n",
            "54    333  100.0   86.0   4.00  258.250000   90.268219   45\n",
            "55   5079   90.0   77.0   3.00  230.911118   86.966820  187\n",
            "56   7529  126.0  107.0   3.00  320.476196  111.572891  644\n",
            "57    622  220.0   79.0   2.75  100.040909   21.231562  219\n",
            "58    930  198.0  125.0   2.25   99.777779   46.072456    5\n",
            "59   6850  162.0   71.0   6.00   57.469135   24.604242  437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Dropout,BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "\n",
        "def custom_activation(x):\n",
        "    #return K.relu(tensorflow.subtract(x,-1)) - K.relu(tensorflow.subtract(x,3.5))\n",
        "    return 4510*1/(1+K.exp(-x))\n",
        "\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(8, input_dim=X_modified.shape[1], activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(32, activation = 'relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(Dense(1, activation = custom_activation))\n",
        "    model.compile(loss='mean_squared_error', optimizer=\"Adam\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "QAi9GPfiMqOX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc2 = StandardScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y, random_state=0, train_size = 0.83)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0, train_size = 0.83)\n",
        "\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test_copy = X_test\n",
        "X_test = sc.transform(X_test)\n",
        "#X_val = sc.transform(X_val)\n",
        "\n",
        "#y_train = sc2.fit_transform(y_train.values.reshape(-1,1))\n",
        "#y_test = sc2.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "estimator = KerasRegressor(build_fn=make_model, epochs=300, batch_size=64, verbose=1)\n",
        "\n",
        "#history=estimator.fit(X_train,y_train)\n",
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 5, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = estimator.fit(X_train, y_train, shuffle = True)\n",
        "#plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqRmSfnjNDi3",
        "outputId": "2fd873cd-55c0-49c8-b5ca-3ba5128396ac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "103/103 [==============================] - 1s 2ms/step - loss: 2146287.7500\n",
            "Epoch 2/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 261271.4219\n",
            "Epoch 3/300\n",
            "103/103 [==============================] - 1s 6ms/step - loss: 86516.2422\n",
            "Epoch 4/300\n",
            "103/103 [==============================] - 1s 5ms/step - loss: 59325.4180\n",
            "Epoch 5/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 50359.7266\n",
            "Epoch 6/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 43814.6641\n",
            "Epoch 7/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 37768.7305\n",
            "Epoch 8/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 31730.6465\n",
            "Epoch 9/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 28499.0020\n",
            "Epoch 10/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 24790.1465\n",
            "Epoch 11/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 22318.0820\n",
            "Epoch 12/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 20678.0957\n",
            "Epoch 13/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 18522.4863\n",
            "Epoch 14/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 18010.0879\n",
            "Epoch 15/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 16626.7266\n",
            "Epoch 16/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 16009.7051\n",
            "Epoch 17/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 15560.4805\n",
            "Epoch 18/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 14937.7441\n",
            "Epoch 19/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 14691.0391\n",
            "Epoch 20/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 14253.9424\n",
            "Epoch 21/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 13934.4941\n",
            "Epoch 22/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 13307.4590\n",
            "Epoch 23/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 13313.5098\n",
            "Epoch 24/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 12629.3232\n",
            "Epoch 25/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 12856.4961\n",
            "Epoch 26/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 12651.1318\n",
            "Epoch 27/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 12235.1797\n",
            "Epoch 28/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 11914.2266\n",
            "Epoch 29/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 12048.9941\n",
            "Epoch 30/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 11422.5000\n",
            "Epoch 31/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 11706.6309\n",
            "Epoch 32/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 11319.5049\n",
            "Epoch 33/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 11146.7520\n",
            "Epoch 34/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 11171.5557\n",
            "Epoch 35/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 11168.0107\n",
            "Epoch 36/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 11110.0508\n",
            "Epoch 37/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10833.7188\n",
            "Epoch 38/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10942.4619\n",
            "Epoch 39/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10785.9688\n",
            "Epoch 40/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10491.0186\n",
            "Epoch 41/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10583.0381\n",
            "Epoch 42/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10602.3320\n",
            "Epoch 43/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10329.5898\n",
            "Epoch 44/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10277.1943\n",
            "Epoch 45/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10251.2979\n",
            "Epoch 46/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 10139.4248\n",
            "Epoch 47/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9789.1553\n",
            "Epoch 48/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9796.4004\n",
            "Epoch 49/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9828.1182\n",
            "Epoch 50/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9815.9346\n",
            "Epoch 51/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9691.5840\n",
            "Epoch 52/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9616.8535\n",
            "Epoch 53/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9433.3418\n",
            "Epoch 54/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9555.9531\n",
            "Epoch 55/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9443.2910\n",
            "Epoch 56/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9346.6143\n",
            "Epoch 57/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9220.0557\n",
            "Epoch 58/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9276.0059\n",
            "Epoch 59/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9121.0938\n",
            "Epoch 60/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 9180.4932\n",
            "Epoch 61/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8904.4844\n",
            "Epoch 62/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8965.6465\n",
            "Epoch 63/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8783.9482\n",
            "Epoch 64/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8673.8857\n",
            "Epoch 65/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8742.4209\n",
            "Epoch 66/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8605.5508\n",
            "Epoch 67/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8391.0186\n",
            "Epoch 68/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8557.1367\n",
            "Epoch 69/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8480.9395\n",
            "Epoch 70/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8435.5410\n",
            "Epoch 71/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8428.1318\n",
            "Epoch 72/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8192.5312\n",
            "Epoch 73/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8266.1973\n",
            "Epoch 74/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8089.3555\n",
            "Epoch 75/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7962.1597\n",
            "Epoch 76/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 8091.8892\n",
            "Epoch 77/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7855.0542\n",
            "Epoch 78/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7853.6855\n",
            "Epoch 79/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7888.7139\n",
            "Epoch 80/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7772.4126\n",
            "Epoch 81/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7894.8140\n",
            "Epoch 82/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7782.7344\n",
            "Epoch 83/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7709.0020\n",
            "Epoch 84/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7487.9580\n",
            "Epoch 85/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7327.9688\n",
            "Epoch 86/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7445.1084\n",
            "Epoch 87/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 7056.5498\n",
            "Epoch 88/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 6936.6646\n",
            "Epoch 89/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 6900.4390\n",
            "Epoch 90/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 6538.5122\n",
            "Epoch 91/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 6420.2925\n",
            "Epoch 92/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 6105.9541\n",
            "Epoch 93/300\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 6008.2104\n",
            "Epoch 94/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 5706.9331\n",
            "Epoch 95/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 5563.1548\n",
            "Epoch 96/300\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 5457.9146\n",
            "Epoch 97/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 5552.3325\n",
            "Epoch 98/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 5458.2803\n",
            "Epoch 99/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 5460.6260\n",
            "Epoch 100/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 5231.2163\n",
            "Epoch 101/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4929.7686\n",
            "Epoch 102/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4973.0176\n",
            "Epoch 103/300\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 5278.5181\n",
            "Epoch 104/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4896.3428\n",
            "Epoch 105/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4924.5767\n",
            "Epoch 106/300\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 4967.6177\n",
            "Epoch 107/300\n",
            "103/103 [==============================] - 0s 3ms/step - loss: 4815.2588\n",
            "Epoch 108/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4754.1099\n",
            "Epoch 109/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4631.9185\n",
            "Epoch 110/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 5034.9277\n",
            "Epoch 111/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4642.3081\n",
            "Epoch 112/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4443.8574\n",
            "Epoch 113/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4736.1304\n",
            "Epoch 114/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4156.3403\n",
            "Epoch 115/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4323.5083\n",
            "Epoch 116/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4282.3672\n",
            "Epoch 117/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4617.4238\n",
            "Epoch 118/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4337.1348\n",
            "Epoch 119/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4634.7324\n",
            "Epoch 120/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4217.7881\n",
            "Epoch 121/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4123.8838\n",
            "Epoch 122/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4262.9341\n",
            "Epoch 123/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4056.8481\n",
            "Epoch 124/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4114.2085\n",
            "Epoch 125/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4126.3018\n",
            "Epoch 126/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4157.2930\n",
            "Epoch 127/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3907.9927\n",
            "Epoch 128/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4042.8469\n",
            "Epoch 129/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4128.7275\n",
            "Epoch 130/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4021.8787\n",
            "Epoch 131/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3764.1953\n",
            "Epoch 132/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 4016.0676\n",
            "Epoch 133/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3991.3311\n",
            "Epoch 134/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3891.5515\n",
            "Epoch 135/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3655.5769\n",
            "Epoch 136/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3527.8931\n",
            "Epoch 137/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3860.4607\n",
            "Epoch 138/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3527.5344\n",
            "Epoch 139/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3549.5354\n",
            "Epoch 140/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3438.3728\n",
            "Epoch 141/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3717.0376\n",
            "Epoch 142/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3689.6848\n",
            "Epoch 143/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3610.0400\n",
            "Epoch 144/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3980.5100\n",
            "Epoch 145/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3363.3110\n",
            "Epoch 146/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3725.4570\n",
            "Epoch 147/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3565.9893\n",
            "Epoch 148/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3422.7095\n",
            "Epoch 149/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3481.4436\n",
            "Epoch 150/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3947.6975\n",
            "Epoch 151/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3386.3130\n",
            "Epoch 152/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3537.3997\n",
            "Epoch 153/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3180.3672\n",
            "Epoch 154/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3568.9548\n",
            "Epoch 155/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3769.5103\n",
            "Epoch 156/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3396.0229\n",
            "Epoch 157/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3362.8516\n",
            "Epoch 158/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3688.4966\n",
            "Epoch 159/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3287.8147\n",
            "Epoch 160/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3407.3491\n",
            "Epoch 161/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3318.3923\n",
            "Epoch 162/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3424.2646\n",
            "Epoch 163/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3402.3652\n",
            "Epoch 164/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3454.7878\n",
            "Epoch 165/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3303.3938\n",
            "Epoch 166/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3497.9072\n",
            "Epoch 167/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3481.4707\n",
            "Epoch 168/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3723.8586\n",
            "Epoch 169/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3209.0242\n",
            "Epoch 170/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3349.9583\n",
            "Epoch 171/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3252.8250\n",
            "Epoch 172/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3319.2644\n",
            "Epoch 173/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3453.7180\n",
            "Epoch 174/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3284.5708\n",
            "Epoch 175/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3273.3357\n",
            "Epoch 176/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3230.1917\n",
            "Epoch 177/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3276.4695\n",
            "Epoch 178/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2926.8582\n",
            "Epoch 179/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3026.4780\n",
            "Epoch 180/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3301.1565\n",
            "Epoch 181/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3538.8301\n",
            "Epoch 182/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3263.4202\n",
            "Epoch 183/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3643.4939\n",
            "Epoch 184/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3361.4231\n",
            "Epoch 185/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3013.9409\n",
            "Epoch 186/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3313.0518\n",
            "Epoch 187/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3198.3240\n",
            "Epoch 188/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3333.3628\n",
            "Epoch 189/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3201.2778\n",
            "Epoch 190/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3214.6350\n",
            "Epoch 191/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3113.5420\n",
            "Epoch 192/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2928.1450\n",
            "Epoch 193/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3504.1572\n",
            "Epoch 194/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3390.5894\n",
            "Epoch 195/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3293.4788\n",
            "Epoch 196/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3106.3088\n",
            "Epoch 197/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2940.4580\n",
            "Epoch 198/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3030.9199\n",
            "Epoch 199/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3241.1208\n",
            "Epoch 200/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3288.7495\n",
            "Epoch 201/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3134.8542\n",
            "Epoch 202/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3229.0642\n",
            "Epoch 203/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3064.8203\n",
            "Epoch 204/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3197.1064\n",
            "Epoch 205/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3142.7354\n",
            "Epoch 206/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3122.3613\n",
            "Epoch 207/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3276.8403\n",
            "Epoch 208/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3159.5037\n",
            "Epoch 209/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3211.3062\n",
            "Epoch 210/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3203.8484\n",
            "Epoch 211/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3130.9436\n",
            "Epoch 212/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3471.9377\n",
            "Epoch 213/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2963.2341\n",
            "Epoch 214/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3213.1506\n",
            "Epoch 215/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3168.6487\n",
            "Epoch 216/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3053.3191\n",
            "Epoch 217/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3184.1670\n",
            "Epoch 218/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3220.4041\n",
            "Epoch 219/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2951.8684\n",
            "Epoch 220/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3191.6699\n",
            "Epoch 221/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3230.4690\n",
            "Epoch 222/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3361.9495\n",
            "Epoch 223/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2830.2000\n",
            "Epoch 224/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3236.6101\n",
            "Epoch 225/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2940.8503\n",
            "Epoch 226/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3148.1633\n",
            "Epoch 227/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3165.3286\n",
            "Epoch 228/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3190.8613\n",
            "Epoch 229/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3110.2437\n",
            "Epoch 230/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3049.8599\n",
            "Epoch 231/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3095.0764\n",
            "Epoch 232/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2953.1460\n",
            "Epoch 233/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3195.5505\n",
            "Epoch 234/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3525.5161\n",
            "Epoch 235/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3138.9153\n",
            "Epoch 236/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3080.1050\n",
            "Epoch 237/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2933.5967\n",
            "Epoch 238/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3174.0947\n",
            "Epoch 239/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3111.8533\n",
            "Epoch 240/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2957.7314\n",
            "Epoch 241/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2929.5449\n",
            "Epoch 242/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3119.7961\n",
            "Epoch 243/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2935.7878\n",
            "Epoch 244/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3233.5559\n",
            "Epoch 245/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2936.2036\n",
            "Epoch 246/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3204.1787\n",
            "Epoch 247/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2954.9863\n",
            "Epoch 248/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2928.9924\n",
            "Epoch 249/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3095.3811\n",
            "Epoch 250/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2828.8955\n",
            "Epoch 251/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3165.8398\n",
            "Epoch 252/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2980.5200\n",
            "Epoch 253/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3064.5066\n",
            "Epoch 254/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2969.8330\n",
            "Epoch 255/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3147.0967\n",
            "Epoch 256/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2809.5708\n",
            "Epoch 257/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3189.6702\n",
            "Epoch 258/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3124.0798\n",
            "Epoch 259/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3021.8948\n",
            "Epoch 260/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2870.5881\n",
            "Epoch 261/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2809.9990\n",
            "Epoch 262/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3083.4194\n",
            "Epoch 263/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2887.4524\n",
            "Epoch 264/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3158.8875\n",
            "Epoch 265/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2931.2068\n",
            "Epoch 266/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3125.1165\n",
            "Epoch 267/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3190.0505\n",
            "Epoch 268/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2747.8623\n",
            "Epoch 269/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2801.6099\n",
            "Epoch 270/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2948.2622\n",
            "Epoch 271/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2899.5867\n",
            "Epoch 272/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3029.6897\n",
            "Epoch 273/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2915.7771\n",
            "Epoch 274/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2769.8638\n",
            "Epoch 275/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3206.8247\n",
            "Epoch 276/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2927.9624\n",
            "Epoch 277/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2843.7214\n",
            "Epoch 278/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3080.1960\n",
            "Epoch 279/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2935.1504\n",
            "Epoch 280/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3004.8484\n",
            "Epoch 281/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2841.8311\n",
            "Epoch 282/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2978.1160\n",
            "Epoch 283/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2742.0010\n",
            "Epoch 284/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2840.6018\n",
            "Epoch 285/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3201.4338\n",
            "Epoch 286/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2950.8115\n",
            "Epoch 287/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3159.4268\n",
            "Epoch 288/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2971.2397\n",
            "Epoch 289/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3132.1938\n",
            "Epoch 290/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3020.2529\n",
            "Epoch 291/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3091.6541\n",
            "Epoch 292/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3026.3826\n",
            "Epoch 293/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2922.9656\n",
            "Epoch 294/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2883.0576\n",
            "Epoch 295/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3107.2822\n",
            "Epoch 296/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 3129.5488\n",
            "Epoch 297/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2778.1184\n",
            "Epoch 298/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2708.6846\n",
            "Epoch 299/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2909.4514\n",
            "Epoch 300/300\n",
            "103/103 [==============================] - 0s 2ms/step - loss: 2869.4287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "prediction = estimator.predict(X_test)\n",
        "print(\"r_square score: \", r2_score(y_test,prediction))\n",
        "#y_test = sc2.inverse_transform(y_test.reshape(-1,1))\n",
        "yy = np.array(y_test)\n",
        "#yy = np.power(yy, 10)/10\n",
        "#prediction = sc2.inverse_transform(prediction.reshape(-1,1))\n",
        "predd = np.array(prediction)\n",
        "#predd = np.power(predd, 10)/10\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "print(\"RMSE:\")\n",
        "sqrt(mean_squared_error(yy, predd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWSUU_tVNL9Y",
        "outputId": "1269dc07-f114-4730-dff2-0e71cc20776b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 1ms/step\n",
            "r_square score:  0.9265532469115046\n",
            "RMSE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53.292772484059334"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yy_temp = []\n",
        "predd_temp = []\n",
        "\n",
        "for i in range(len(yy)):\n",
        "  if(yy[i]>=10 and yy[i]<1000):\n",
        "    yy_temp.append(yy[i])\n",
        "    predd_temp.append(predd[i])\n",
        "\n",
        "plt.scatter(yy_temp, predd_temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "kr8vuMOtNf7g",
        "outputId": "43ec25fb-efdf-4f77-9e38-a8b6f1ce7b8d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f8b10818590>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled = df_reg0.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = ['y', 'index', 'inst.name','type', 'CPLEXStatus']\n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']\n",
        "X_modified = X"
      ],
      "metadata": {
        "id": "a6jZD4deYNxu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "oversample = RandomOverSampler(random_state=0)\n",
        "X_modified, y = oversample.fit_resample(X_modified, y.astype('int'))\n",
        "print(X_modified.shape[0])\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote_on_3 = 50\n",
        "#oversample = SMOTE(sampling_strategy={99999:50000})\n",
        "#X_modified, y = oversample.fit_resample(X_modified, y)\n",
        "print(X_modified.shape[0])\n",
        "\n",
        "tmp = X_modified\n",
        "tmp['y'] = y\n",
        "print(tmp.head(60))\n",
        "tmp = tmp.sample(frac = 1).reset_index()\n",
        "#y = np.log10(tmp['y']*10)+20\n",
        "tmp = tmp.dropna()\n",
        "y = tmp['y']\n",
        "X_modified = tmp.drop(['y'], axis = 1)"
      ],
      "metadata": {
        "id": "V6TdX9OKYWgi",
        "outputId": "27251a2c-dff2-4950-b0f3-4078f6b84061",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3432\n",
            "3432\n",
            "        n     k     m    std.dev   y\n",
            "0    40.0  32.0  16.0  16.090271   2\n",
            "1    18.0  17.0   6.0  28.893766   0\n",
            "2    18.0  16.0   3.0  25.950176   0\n",
            "3    20.0  19.0   5.0  43.534622   0\n",
            "4    20.0  18.0   5.0  17.910303   0\n",
            "5    36.0  32.0  16.0  54.048389   1\n",
            "6    44.0  30.0  16.0  21.785713   3\n",
            "7    54.0  30.0  18.0  14.755259   6\n",
            "8    60.0  45.0  24.0  23.251089   5\n",
            "9    44.0  31.0  16.0  14.316327   4\n",
            "10   18.0  18.0   2.0  52.771675   1\n",
            "11   54.0  38.0  24.0  14.938553   3\n",
            "12   22.0  19.0   8.0  19.110298   0\n",
            "13   54.0  40.0  18.0  19.775089   8\n",
            "14   18.0  16.0   8.0  12.701321   0\n",
            "15  126.0  86.0  56.0  41.774616  11\n",
            "16   72.0  60.0  32.0  64.198402   4\n",
            "17   20.0  18.0  10.0  16.929808   0\n",
            "18   22.0  20.0   8.0  18.840927   0\n",
            "19   22.0  20.0   8.0  53.170414   0\n",
            "20   36.0  31.0   8.0  41.549625  11\n",
            "21   18.0  16.0   4.0  23.887539   0\n",
            "22   54.0  39.0  12.0  29.756241   8\n",
            "23   44.0  35.0  16.0  41.860203   8\n",
            "24   72.0  56.0  32.0  42.463898  11\n",
            "25   18.0  14.0   3.0  13.115998   0\n",
            "26   36.0  25.0   6.0  15.422618   2\n",
            "27   40.0  33.0  10.0  36.477039  11\n",
            "28   60.0  42.0  24.0  23.682283   7\n",
            "29   54.0  49.0  18.0  54.929371   9\n",
            "30   20.0  16.0   2.0  15.661804   3\n",
            "31   36.0  28.0   6.0  27.092596  11\n",
            "32   18.0  17.0   8.0  14.087147   0\n",
            "33   36.0  29.0  12.0  22.020050   2\n",
            "34   36.0  32.0  16.0  31.432808   2\n",
            "35   18.0  16.0   6.0  26.194159   0\n",
            "36   18.0  16.0   6.0  26.194159   0\n",
            "37   36.0  28.0   4.0  27.092596  11\n",
            "38   60.0  47.0  30.0  43.933254   1\n",
            "39   80.0  41.0  32.0  15.193471  11\n",
            "40   18.0  16.0   2.0  22.836733   0\n",
            "41   36.0  23.0  16.0  15.283017   1\n",
            "42   44.0  43.0  16.0  43.853661  11\n",
            "43   20.0  17.0  10.0  15.812304   0\n",
            "44   22.0  18.0   8.0  18.501726   1\n",
            "45   18.0  17.0   3.0  19.159206   0\n",
            "46   20.0  17.0   4.0  18.250523   0\n",
            "47   36.0  29.0  16.0  20.577595   1\n",
            "48   20.0  17.0   4.0  20.545904   2\n",
            "49   20.0  20.0   8.0  13.862007   0\n",
            "50   40.0  29.0  16.0  20.173861   3\n",
            "51   18.0  18.0   3.0  27.304863   1\n",
            "52  126.0  89.0  56.0  49.460457   3\n",
            "53   18.0  14.0   8.0  15.166720   0\n",
            "54   20.0  17.0   2.0  21.050314   1\n",
            "55   36.0  28.0   8.0  14.388487   4\n",
            "56  126.0  84.0  56.0  48.069668   2\n",
            "57   18.0  14.0   6.0  13.301064   0\n",
            "58   18.0  18.0   6.0  31.704931   0\n",
            "59   18.0  14.0   3.0  13.301064   0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Dropout,BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "\n",
        "def custom_activation(x):\n",
        "    #return K.relu(tensorflow.subtract(x,-1)) - K.relu(tensorflow.subtract(x,3.5))\n",
        "    return 10*1/(1+K.exp(-x))\n",
        "\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(8, input_dim=X_modified.shape[1], activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(12, activation = 'relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(Dense(1, activation = custom_activation))\n",
        "    model.compile(loss='mean_squared_error', optimizer='Adam')\n",
        "    return model"
      ],
      "metadata": {
        "id": "nn0lOzP3YcUq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc2 = StandardScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y, random_state=0, train_size = 0.83)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0, train_size = 0.83)\n",
        "\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test_copy = X_test\n",
        "X_test = sc.transform(X_test)\n",
        "#X_val = sc.transform(X_val)\n",
        "\n",
        "#y_train = sc2.fit_transform(y_train.values.reshape(-1,1))\n",
        "#y_test = sc2.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "estimator = KerasRegressor(build_fn=make_model, epochs=300, batch_size=64, verbose=1)\n",
        "\n",
        "#history=estimator.fit(X_train,y_train)\n",
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 5, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = estimator.fit(X_train, y_train, shuffle = True)\n",
        "#plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "id": "ms0Uyv45YmQH",
        "outputId": "058f4ecc-6732-47ec-dcca-4633618d566b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 1s 2ms/step - loss: 9.2396\n",
            "Epoch 2/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 7.5114\n",
            "Epoch 3/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 5.8230\n",
            "Epoch 4/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 4.6216\n",
            "Epoch 5/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.9511\n",
            "Epoch 6/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.6788\n",
            "Epoch 7/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.4886\n",
            "Epoch 8/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.4111\n",
            "Epoch 9/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.2416\n",
            "Epoch 10/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 3.0669\n",
            "Epoch 11/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.8684\n",
            "Epoch 12/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.8385\n",
            "Epoch 13/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.7226\n",
            "Epoch 14/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.7067\n",
            "Epoch 15/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.6232\n",
            "Epoch 16/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.4963\n",
            "Epoch 17/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.4454\n",
            "Epoch 18/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.3609\n",
            "Epoch 19/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.2652\n",
            "Epoch 20/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.2793\n",
            "Epoch 21/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.2031\n",
            "Epoch 22/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.2059\n",
            "Epoch 23/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.1157\n",
            "Epoch 24/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.0719\n",
            "Epoch 25/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.0001\n",
            "Epoch 26/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.0373\n",
            "Epoch 27/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 2.0282\n",
            "Epoch 28/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.9426\n",
            "Epoch 29/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.9722\n",
            "Epoch 30/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.9109\n",
            "Epoch 31/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.9164\n",
            "Epoch 32/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8833\n",
            "Epoch 33/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8847\n",
            "Epoch 34/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8215\n",
            "Epoch 35/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8348\n",
            "Epoch 36/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8706\n",
            "Epoch 37/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.8379\n",
            "Epoch 38/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7728\n",
            "Epoch 39/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7401\n",
            "Epoch 40/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7462\n",
            "Epoch 41/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7104\n",
            "Epoch 42/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7552\n",
            "Epoch 43/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7097\n",
            "Epoch 44/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7389\n",
            "Epoch 45/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6766\n",
            "Epoch 46/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6863\n",
            "Epoch 47/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7063\n",
            "Epoch 48/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6878\n",
            "Epoch 49/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6941\n",
            "Epoch 50/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.7145\n",
            "Epoch 51/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6793\n",
            "Epoch 52/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6958\n",
            "Epoch 53/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6332\n",
            "Epoch 54/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6345\n",
            "Epoch 55/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6140\n",
            "Epoch 56/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6061\n",
            "Epoch 57/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6189\n",
            "Epoch 58/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6153\n",
            "Epoch 59/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6002\n",
            "Epoch 60/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6504\n",
            "Epoch 61/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5897\n",
            "Epoch 62/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5716\n",
            "Epoch 63/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6410\n",
            "Epoch 64/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5742\n",
            "Epoch 65/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6004\n",
            "Epoch 66/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5718\n",
            "Epoch 67/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5943\n",
            "Epoch 68/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5811\n",
            "Epoch 69/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5819\n",
            "Epoch 70/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5582\n",
            "Epoch 71/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5571\n",
            "Epoch 72/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5777\n",
            "Epoch 73/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5887\n",
            "Epoch 74/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5947\n",
            "Epoch 75/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.6139\n",
            "Epoch 76/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5565\n",
            "Epoch 77/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5365\n",
            "Epoch 78/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5405\n",
            "Epoch 79/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5518\n",
            "Epoch 80/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5417\n",
            "Epoch 81/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5246\n",
            "Epoch 82/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5572\n",
            "Epoch 83/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5077\n",
            "Epoch 84/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5062\n",
            "Epoch 85/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5213\n",
            "Epoch 86/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5456\n",
            "Epoch 87/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4993\n",
            "Epoch 88/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5399\n",
            "Epoch 89/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5470\n",
            "Epoch 90/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5550\n",
            "Epoch 91/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4804\n",
            "Epoch 92/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5052\n",
            "Epoch 93/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5263\n",
            "Epoch 94/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5560\n",
            "Epoch 95/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5205\n",
            "Epoch 96/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5230\n",
            "Epoch 97/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4527\n",
            "Epoch 98/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5179\n",
            "Epoch 99/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4655\n",
            "Epoch 100/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5148\n",
            "Epoch 101/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5091\n",
            "Epoch 102/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5080\n",
            "Epoch 103/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5183\n",
            "Epoch 104/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4905\n",
            "Epoch 105/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5151\n",
            "Epoch 106/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4887\n",
            "Epoch 107/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5155\n",
            "Epoch 108/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4934\n",
            "Epoch 109/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5240\n",
            "Epoch 110/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4755\n",
            "Epoch 111/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4366\n",
            "Epoch 112/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4173\n",
            "Epoch 113/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4413\n",
            "Epoch 114/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4601\n",
            "Epoch 115/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4529\n",
            "Epoch 116/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4728\n",
            "Epoch 117/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4716\n",
            "Epoch 118/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.5153\n",
            "Epoch 119/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4085\n",
            "Epoch 120/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4457\n",
            "Epoch 121/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4065\n",
            "Epoch 122/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4615\n",
            "Epoch 123/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4314\n",
            "Epoch 124/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4392\n",
            "Epoch 125/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4199\n",
            "Epoch 126/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4489\n",
            "Epoch 127/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4473\n",
            "Epoch 128/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3767\n",
            "Epoch 129/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4355\n",
            "Epoch 130/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4215\n",
            "Epoch 131/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4351\n",
            "Epoch 132/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4205\n",
            "Epoch 133/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4007\n",
            "Epoch 134/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4243\n",
            "Epoch 135/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4036\n",
            "Epoch 136/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3967\n",
            "Epoch 137/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3987\n",
            "Epoch 138/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3964\n",
            "Epoch 139/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3993\n",
            "Epoch 140/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3966\n",
            "Epoch 141/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4219\n",
            "Epoch 142/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3819\n",
            "Epoch 143/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4294\n",
            "Epoch 144/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3701\n",
            "Epoch 145/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4258\n",
            "Epoch 146/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4283\n",
            "Epoch 147/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3871\n",
            "Epoch 148/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4112\n",
            "Epoch 149/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3877\n",
            "Epoch 150/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3501\n",
            "Epoch 151/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3697\n",
            "Epoch 152/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3437\n",
            "Epoch 153/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3898\n",
            "Epoch 154/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3670\n",
            "Epoch 155/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3849\n",
            "Epoch 156/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3974\n",
            "Epoch 157/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3974\n",
            "Epoch 158/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3999\n",
            "Epoch 159/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3328\n",
            "Epoch 160/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3930\n",
            "Epoch 161/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3822\n",
            "Epoch 162/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3558\n",
            "Epoch 163/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3451\n",
            "Epoch 164/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3704\n",
            "Epoch 165/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4157\n",
            "Epoch 166/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3444\n",
            "Epoch 167/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3786\n",
            "Epoch 168/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3593\n",
            "Epoch 169/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3312\n",
            "Epoch 170/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3937\n",
            "Epoch 171/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3588\n",
            "Epoch 172/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3265\n",
            "Epoch 173/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3956\n",
            "Epoch 174/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3183\n",
            "Epoch 175/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3260\n",
            "Epoch 176/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3312\n",
            "Epoch 177/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3350\n",
            "Epoch 178/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3576\n",
            "Epoch 179/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3697\n",
            "Epoch 180/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3455\n",
            "Epoch 181/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.4083\n",
            "Epoch 182/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3602\n",
            "Epoch 183/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3518\n",
            "Epoch 184/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3487\n",
            "Epoch 185/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3240\n",
            "Epoch 186/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2919\n",
            "Epoch 187/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3047\n",
            "Epoch 188/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3342\n",
            "Epoch 189/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3164\n",
            "Epoch 190/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3544\n",
            "Epoch 191/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3536\n",
            "Epoch 192/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3401\n",
            "Epoch 193/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3532\n",
            "Epoch 194/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2882\n",
            "Epoch 195/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2937\n",
            "Epoch 196/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3552\n",
            "Epoch 197/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3278\n",
            "Epoch 198/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3426\n",
            "Epoch 199/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3124\n",
            "Epoch 200/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3295\n",
            "Epoch 201/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3684\n",
            "Epoch 202/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2857\n",
            "Epoch 203/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3320\n",
            "Epoch 204/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3248\n",
            "Epoch 205/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3496\n",
            "Epoch 206/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2786\n",
            "Epoch 207/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2833\n",
            "Epoch 208/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3243\n",
            "Epoch 209/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2943\n",
            "Epoch 210/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3182\n",
            "Epoch 211/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3190\n",
            "Epoch 212/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2988\n",
            "Epoch 213/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3531\n",
            "Epoch 214/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3314\n",
            "Epoch 215/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3374\n",
            "Epoch 216/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2972\n",
            "Epoch 217/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3446\n",
            "Epoch 218/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3047\n",
            "Epoch 219/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2761\n",
            "Epoch 220/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3053\n",
            "Epoch 221/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2783\n",
            "Epoch 222/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3222\n",
            "Epoch 223/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3162\n",
            "Epoch 224/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2851\n",
            "Epoch 225/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2819\n",
            "Epoch 226/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3208\n",
            "Epoch 227/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2909\n",
            "Epoch 228/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3006\n",
            "Epoch 229/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3326\n",
            "Epoch 230/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2408\n",
            "Epoch 231/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2956\n",
            "Epoch 232/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3245\n",
            "Epoch 233/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3333\n",
            "Epoch 234/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3451\n",
            "Epoch 235/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2787\n",
            "Epoch 236/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3024\n",
            "Epoch 237/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2978\n",
            "Epoch 238/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2798\n",
            "Epoch 239/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3394\n",
            "Epoch 240/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2872\n",
            "Epoch 241/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2849\n",
            "Epoch 242/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3017\n",
            "Epoch 243/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3058\n",
            "Epoch 244/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3067\n",
            "Epoch 245/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3228\n",
            "Epoch 246/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2786\n",
            "Epoch 247/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2508\n",
            "Epoch 248/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3368\n",
            "Epoch 249/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3101\n",
            "Epoch 250/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3271\n",
            "Epoch 251/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2366\n",
            "Epoch 252/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2831\n",
            "Epoch 253/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2772\n",
            "Epoch 254/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2801\n",
            "Epoch 255/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2964\n",
            "Epoch 256/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3080\n",
            "Epoch 257/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2793\n",
            "Epoch 258/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2980\n",
            "Epoch 259/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2784\n",
            "Epoch 260/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2717\n",
            "Epoch 261/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2813\n",
            "Epoch 262/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2993\n",
            "Epoch 263/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2899\n",
            "Epoch 264/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2593\n",
            "Epoch 265/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2907\n",
            "Epoch 266/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2918\n",
            "Epoch 267/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2958\n",
            "Epoch 268/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2623\n",
            "Epoch 269/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2594\n",
            "Epoch 270/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3088\n",
            "Epoch 271/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2633\n",
            "Epoch 272/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2488\n",
            "Epoch 273/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3032\n",
            "Epoch 274/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2730\n",
            "Epoch 275/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2461\n",
            "Epoch 276/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2806\n",
            "Epoch 277/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3354\n",
            "Epoch 278/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2732\n",
            "Epoch 279/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2776\n",
            "Epoch 280/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3037\n",
            "Epoch 281/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2921\n",
            "Epoch 282/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2644\n",
            "Epoch 283/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2801\n",
            "Epoch 284/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2910\n",
            "Epoch 285/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2870\n",
            "Epoch 286/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2462\n",
            "Epoch 287/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2503\n",
            "Epoch 288/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2502\n",
            "Epoch 289/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2342\n",
            "Epoch 290/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2689\n",
            "Epoch 291/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2853\n",
            "Epoch 292/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2696\n",
            "Epoch 293/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2616\n",
            "Epoch 294/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2561\n",
            "Epoch 295/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2480\n",
            "Epoch 296/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2571\n",
            "Epoch 297/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.3081\n",
            "Epoch 298/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2669\n",
            "Epoch 299/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2492\n",
            "Epoch 300/300\n",
            "45/45 [==============================] - 0s 2ms/step - loss: 1.2705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "prediction = estimator.predict(X_test)\n",
        "print(\"r_square score: \", r2_score(y_test,prediction))\n",
        "#y_test = sc2.inverse_transform(y_test.reshape(-1,1))\n",
        "yy = np.array(y_test)\n",
        "#yy = np.power(yy, 10)/10\n",
        "#prediction = sc2.inverse_transform(prediction.reshape(-1,1))\n",
        "predd = np.array(prediction)\n",
        "#predd = np.power(predd, 10)/10\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "print(\"RMSE:\")\n",
        "sqrt(mean_squared_error(yy, predd))"
      ],
      "metadata": {
        "id": "eIc68VmrYsto",
        "outputId": "14ef1372-1f67-48f5-b802-4ecb85a348e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "r_square score:  0.8881918535683422\n",
            "RMSE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.081446592003078"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yy_temp = []\n",
        "predd_temp = []\n",
        "\n",
        "for i in range(len(yy)):\n",
        "  if(yy[i]<10):\n",
        "    yy_temp.append(yy[i])\n",
        "    predd_temp.append(predd[i])\n",
        "\n",
        "plt.scatter(yy_temp, predd_temp)"
      ],
      "metadata": {
        "id": "CojAurDyY1dF",
        "outputId": "f26ea0cf-6a6c-4162-f2db-75b9edf27a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f8b10691ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled = df_reg2.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = ['y', 'index', 'inst.name','type', 'CPLEXStatus']\n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']\n",
        "X_modified = X"
      ],
      "metadata": {
        "id": "3UEPEdxNgQ8k"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "oversample = RandomOverSampler(random_state=0)\n",
        "X_modified, y = oversample.fit_resample(X_modified, y.astype('int'))\n",
        "print(X_modified.shape[0])\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote_on_3 = 50\n",
        "#oversample = SMOTE(sampling_strategy={99999:50000})\n",
        "#X_modified, y = oversample.fit_resample(X_modified, y)\n",
        "print(X_modified.shape[0])\n",
        "\n",
        "tmp = X_modified\n",
        "tmp['y'] = y\n",
        "print(tmp.head(60))\n",
        "tmp = tmp.sample(frac = 1).reset_index()\n",
        "#y = np.log10(tmp['y']*10)+20\n",
        "tmp = tmp.dropna()\n",
        "y = tmp['y']\n",
        "X_modified = tmp.drop(['y'], axis = 1)"
      ],
      "metadata": {
        "id": "IWjG8zhvgS57",
        "outputId": "700654be-b307-4555-df24-7c5a26b6819e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158574\n",
            "158574\n",
            "        n      k   av.length     std.dev     y\n",
            "0   126.0  107.0  501.873016  128.004990  4510\n",
            "1   198.0  175.0  780.762634  210.685165  4510\n",
            "2   180.0  112.0  101.466667   50.076527  4510\n",
            "3   162.0   73.0   57.500000   23.256935  1077\n",
            "4   160.0   68.0   98.612503   18.766016  4510\n",
            "5   220.0   79.0  100.040909   21.231562  4510\n",
            "6   154.0   67.0  101.746750   19.346022  4510\n",
            "7   144.0  121.0  373.298615  131.739197  4510\n",
            "8   126.0  107.0  312.523804  109.223129  4510\n",
            "9   100.0   56.0   99.040001   18.877554  1717\n",
            "10  120.0   87.0   93.183334   47.574444  4510\n",
            "11  120.0   87.0   93.183334   47.574444  4510\n",
            "12  200.0  119.0  101.699997   49.112724  4510\n",
            "13  162.0  136.0  399.481476  136.154510  4510\n",
            "14  200.0  125.0  101.815002   50.574791  4510\n",
            "15  108.0   89.0  442.814819  105.392731  4510\n",
            "16  144.0  121.0  349.583344  125.159943  4510\n",
            "17  198.0  172.0  508.691925  167.474625  4510\n",
            "18  144.0  101.0   96.645836   45.839096  4510\n",
            "19   80.0   68.0  326.762512   76.749016  4510\n",
            "20   60.0   56.0  236.066666   65.307846  4510\n",
            "21  160.0  133.0  652.887512  156.741806  4510\n",
            "22  176.0   73.0   98.227272   21.246700  4510\n",
            "23  200.0   86.0   47.115002   30.439852  1305\n",
            "24  126.0   99.0  307.134918  106.701698  4510\n",
            "25  198.0  178.0  794.535339  192.643173  4510\n",
            "26  108.0   93.0  275.944458   88.826408  4510\n",
            "27  200.0  119.0  101.699997   49.112724  4510\n",
            "28  180.0  154.0  443.727783  153.247818  4510\n",
            "29  132.0  119.0  527.098511  136.828018  4510\n",
            "30  100.0   86.0  237.240005   83.270164  4510\n",
            "31  120.0   99.0  288.391663  106.842712  4510\n",
            "32  180.0   71.0   62.422222   24.652437  1450\n",
            "33  200.0   75.0  100.500000   20.163900   812\n",
            "34  198.0  167.0  526.237366  165.901825  4510\n",
            "35   80.0   71.0  197.987503   69.608765  4510\n",
            "36  198.0  173.0  772.727295  191.971680  4510\n",
            "37  180.0  159.0  717.955566  185.726913   463\n",
            "38  180.0  113.0  106.216667   47.778267  4510\n",
            "39  100.0   77.0  103.959999   45.550266  4510\n",
            "40   90.0   82.0  215.477783   77.425171  4510\n",
            "41  198.0  172.0  792.474731  216.066925  4510\n",
            "42  140.0   66.0   99.121429   20.696663  1492\n",
            "43  198.0   49.0   75.530304   15.645393  4510\n",
            "44  140.0  119.0  553.178589  125.851715  4510\n",
            "45  108.0   82.0  109.407410   48.678619  4510\n",
            "46  176.0  148.0  701.250000  166.354355  4510\n",
            "47  198.0  166.0  490.202026  171.781097  4510\n",
            "48  220.0   91.0   49.590908   27.529743  1125\n",
            "49  140.0  119.0  553.178589  125.851715  4510\n",
            "50  120.0  100.0  319.049988  109.162712  4510\n",
            "51   88.0   49.0   60.863636   24.069431   699\n",
            "52  220.0  186.0  528.418152  189.115936  4510\n",
            "53  198.0   91.0   53.469696   29.838593  1918\n",
            "54  220.0   77.0   60.995453   23.289621  4510\n",
            "55  132.0   91.0  102.204544   48.952816  4510\n",
            "56  154.0  132.0  623.623352  147.898132  1668\n",
            "57  198.0  174.0  791.025269  196.622818  4510\n",
            "58   80.0   66.0  106.937500   48.509495  4510\n",
            "59   80.0   68.0  306.312500   73.349426  4510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Dropout,BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.python.ops import math_ops\n",
        "\n",
        "\n",
        "def custom_activation(x):\n",
        "    #return K.relu(tensorflow.subtract(x,-1)) - K.relu(tensorflow.subtract(x,3.5))\n",
        "    return 4510*1/(1+K.exp(-x))\n",
        "\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(8, input_dim=X_modified.shape[1], activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(12, activation = 'relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(Dense(1, activation = custom_activation))\n",
        "    model.compile(loss='mean_squared_error', optimizer='Adam')\n",
        "    return model"
      ],
      "metadata": {
        "id": "Luwo5AkigdEG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc2 = StandardScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y, random_state=0, train_size = 0.83)\n",
        "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0, train_size = 0.83)\n",
        "\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test_copy = X_test\n",
        "X_test = sc.transform(X_test)\n",
        "#X_val = sc.transform(X_val)\n",
        "\n",
        "#y_train = sc2.fit_transform(y_train.values.reshape(-1,1))\n",
        "#y_test = sc2.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "estimator = KerasRegressor(build_fn=make_model, epochs=30, batch_size=64, verbose=1)\n",
        "\n",
        "#history=estimator.fit(X_train,y_train)\n",
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 5, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = estimator.fit(X_train, y_train, shuffle = True)\n",
        "#plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "id": "apyKMbpJgne2",
        "outputId": "4b930e12-bb79-4909-a033-cc5289931408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2057/2057 [==============================] - 4s 2ms/step - loss: 198029.0938\n",
            "Epoch 2/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 103536.7812\n",
            "Epoch 3/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 100356.9062\n",
            "Epoch 4/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 98808.0859\n",
            "Epoch 5/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 98107.7031\n",
            "Epoch 6/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 98048.5703\n",
            "Epoch 7/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 97325.3359\n",
            "Epoch 8/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 97500.4453\n",
            "Epoch 9/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 97171.5000\n",
            "Epoch 10/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 96863.4609\n",
            "Epoch 11/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 96478.9531\n",
            "Epoch 12/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 96350.1719\n",
            "Epoch 13/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 95973.4297\n",
            "Epoch 14/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 96268.7656\n",
            "Epoch 15/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 95977.5703\n",
            "Epoch 16/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 95348.9844\n",
            "Epoch 17/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 95124.0859\n",
            "Epoch 18/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 95011.1875\n",
            "Epoch 19/30\n",
            "2057/2057 [==============================] - 5s 2ms/step - loss: 95049.1328\n",
            "Epoch 20/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 95020.1094\n",
            "Epoch 21/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94659.5938\n",
            "Epoch 22/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94625.6328\n",
            "Epoch 23/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94172.5469\n",
            "Epoch 24/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94416.7969\n",
            "Epoch 25/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94590.1250\n",
            "Epoch 26/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94478.3047\n",
            "Epoch 27/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94440.4219\n",
            "Epoch 28/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94371.5312\n",
            "Epoch 29/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94333.8672\n",
            "Epoch 30/30\n",
            "2057/2057 [==============================] - 3s 2ms/step - loss: 94521.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "prediction = estimator.predict(X_test)\n",
        "print(\"r_square score: \", r2_score(y_test,prediction))\n",
        "#y_test = sc2.inverse_transform(y_test.reshape(-1,1))\n",
        "yy = np.array(y_test)\n",
        "#yy = np.power(yy, 10)/10\n",
        "#prediction = sc2.inverse_transform(prediction.reshape(-1,1))\n",
        "predd = np.array(prediction)\n",
        "#predd = np.power(predd, 10)/10\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "print(\"RMSE:\")\n",
        "sqrt(mean_squared_error(yy, predd))"
      ],
      "metadata": {
        "id": "D-D2S_qagoEL",
        "outputId": "b9029f30-fd25-476a-a271-464f377b36fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "422/422 [==============================] - 1s 1ms/step\n",
            "r_square score:  0.9275906641447448\n",
            "RMSE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "306.21826909604675"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yy_temp = []\n",
        "predd_temp = []\n",
        "\n",
        "for i in range(len(yy)):\n",
        "  if(yy[i]>1000):\n",
        "    yy_temp.append(yy[i])\n",
        "    predd_temp.append(predd[i])\n",
        "\n",
        "plt.scatter(yy_temp, predd_temp)"
      ],
      "metadata": {
        "id": "2ezns0RWgtkq",
        "outputId": "29e9db1a-6cd6-4307-f9a2-508be314f047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f8b103fb310>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}