{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1iFfIF/XbgrtYmQ1qjnyV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uros-Males/Minimization_Problem_On_Identical_Machines_Analysis/blob/main/Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YiQcuNkDxHUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2037fae-8465-4049-c789-278a84ec64f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8750\n"
          ]
        }
      ],
      "source": [
        "#IN PROGRESS....\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import time\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/C-instances-runtime-analysis.csv')\n",
        "print(df.shape[0])\n",
        "\n",
        "shuffled = df.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = ['y', 'index', 'inst.name', 'CPLEXStatus','type']\n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_modified = X.drop(['max', 'n/m', '(n/m)^2', '(n/m)^3', 'm/n', '(m/n)^2', '(m/n)^3', 'class', 'av.length'], axis = 1)"
      ],
      "metadata": {
        "id": "Jzlk_oaRyQjm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Dropout,BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras \n",
        "\n",
        "\n",
        "def custom_activation(x):\n",
        "    return 99999*1/(1+K.exp(-x))\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(8, input_dim=X_modified.shape[1], activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    \n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    #model.add(Dropout(0.15))\n",
        "    \n",
        "    model.add(Dense(4, activation='relu'))\n",
        "    \n",
        "    model.add(Dense(1, activation = custom_activation))\n",
        "    #model.add(Activation(custom_activation, name='SpecialActivation'))\n",
        "    model.compile(loss='mean_squared_error', optimizer=tensorflow.keras.optimizers.Adam(clipnorm=1))\n",
        "    return model"
      ],
      "metadata": {
        "id": "7_m2qFDRya94"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler =  MinMaxScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y, random_state=0, train_size = 0.83)\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "estimator = KerasRegressor(build_fn=make_model, epochs=300, batch_size=32, verbose=1)\n",
        "\n",
        "#history=estimator.fit(X_train,y_train)\n",
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 25, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = estimator.fit(X_train, y_train, validation_data =(X_test, y_test), \n",
        "                    callbacks =[earlystopping])\n",
        "#plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JHin8gI5ftQ",
        "outputId": "2cacf2f4-b359-44bf-fac3-7c71699fdea4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "227/227 [==============================] - 3s 5ms/step - loss: 1683202048.0000 - val_loss: 1074517248.0000\n",
            "Epoch 2/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 746123072.0000 - val_loss: 458605696.0000\n",
            "Epoch 3/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 368785664.0000 - val_loss: 352326944.0000\n",
            "Epoch 4/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 323032512.0000 - val_loss: 332866624.0000\n",
            "Epoch 5/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 310608672.0000 - val_loss: 302472448.0000\n",
            "Epoch 6/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 309160480.0000 - val_loss: 364430400.0000\n",
            "Epoch 7/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 309781088.0000 - val_loss: 296250624.0000\n",
            "Epoch 8/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 300615904.0000 - val_loss: 323432352.0000\n",
            "Epoch 9/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 291855680.0000 - val_loss: 327958976.0000\n",
            "Epoch 10/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 300236640.0000 - val_loss: 314869312.0000\n",
            "Epoch 11/300\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 298833088.0000 - val_loss: 320471904.0000\n",
            "Epoch 12/300\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 295541856.0000 - val_loss: 295751648.0000\n",
            "Epoch 13/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 292858080.0000 - val_loss: 305712928.0000\n",
            "Epoch 14/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 293114720.0000 - val_loss: 295747360.0000\n",
            "Epoch 15/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 284759744.0000 - val_loss: 307324512.0000\n",
            "Epoch 16/300\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 282502784.0000 - val_loss: 284237568.0000\n",
            "Epoch 17/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 281912928.0000 - val_loss: 275494176.0000\n",
            "Epoch 18/300\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 282205280.0000 - val_loss: 314648384.0000\n",
            "Epoch 19/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 291216800.0000 - val_loss: 311084512.0000\n",
            "Epoch 20/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 276852320.0000 - val_loss: 268803136.0000\n",
            "Epoch 21/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 271401600.0000 - val_loss: 267224256.0000\n",
            "Epoch 22/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 269085312.0000 - val_loss: 293743232.0000\n",
            "Epoch 23/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 276592448.0000 - val_loss: 261175120.0000\n",
            "Epoch 24/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 260161136.0000 - val_loss: 273955072.0000\n",
            "Epoch 25/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 266567616.0000 - val_loss: 331748096.0000\n",
            "Epoch 26/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 261412512.0000 - val_loss: 247842192.0000\n",
            "Epoch 27/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 257035072.0000 - val_loss: 314902080.0000\n",
            "Epoch 28/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 260841424.0000 - val_loss: 236172608.0000\n",
            "Epoch 29/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 262890816.0000 - val_loss: 250515104.0000\n",
            "Epoch 30/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 253208608.0000 - val_loss: 239801072.0000\n",
            "Epoch 31/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 247608832.0000 - val_loss: 255176896.0000\n",
            "Epoch 32/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 246749360.0000 - val_loss: 227223536.0000\n",
            "Epoch 33/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 234745824.0000 - val_loss: 227348240.0000\n",
            "Epoch 34/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 246209712.0000 - val_loss: 252951504.0000\n",
            "Epoch 35/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 234410128.0000 - val_loss: 239816944.0000\n",
            "Epoch 36/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 245005248.0000 - val_loss: 222920992.0000\n",
            "Epoch 37/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 234449872.0000 - val_loss: 294010176.0000\n",
            "Epoch 38/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 246684144.0000 - val_loss: 222186240.0000\n",
            "Epoch 39/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 234416912.0000 - val_loss: 216888272.0000\n",
            "Epoch 40/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 227493152.0000 - val_loss: 232913728.0000\n",
            "Epoch 41/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 233034480.0000 - val_loss: 217521888.0000\n",
            "Epoch 42/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236348016.0000 - val_loss: 217009520.0000\n",
            "Epoch 43/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 240746224.0000 - val_loss: 258362800.0000\n",
            "Epoch 44/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 246832336.0000 - val_loss: 216644512.0000\n",
            "Epoch 45/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 229072016.0000 - val_loss: 246515984.0000\n",
            "Epoch 46/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236323792.0000 - val_loss: 238493824.0000\n",
            "Epoch 47/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 258167360.0000 - val_loss: 235746080.0000\n",
            "Epoch 48/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 232400464.0000 - val_loss: 261603856.0000\n",
            "Epoch 49/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 240830704.0000 - val_loss: 280323552.0000\n",
            "Epoch 50/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 247368080.0000 - val_loss: 234918832.0000\n",
            "Epoch 51/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236155968.0000 - val_loss: 225522896.0000\n",
            "Epoch 52/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 248291328.0000 - val_loss: 248869920.0000\n",
            "Epoch 53/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 231071904.0000 - val_loss: 232296048.0000\n",
            "Epoch 54/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 242491088.0000 - val_loss: 244267472.0000\n",
            "Epoch 55/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 233343024.0000 - val_loss: 247463664.0000\n",
            "Epoch 56/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 234555968.0000 - val_loss: 252560752.0000\n",
            "Epoch 57/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 240925872.0000 - val_loss: 258988096.0000\n",
            "Epoch 58/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 233738672.0000 - val_loss: 227654336.0000\n",
            "Epoch 59/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 233125888.0000 - val_loss: 248037904.0000\n",
            "Epoch 60/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237623712.0000 - val_loss: 231546336.0000\n",
            "Epoch 61/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 224311824.0000 - val_loss: 256693568.0000\n",
            "Epoch 62/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 239018992.0000 - val_loss: 224199824.0000\n",
            "Epoch 63/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 232747264.0000 - val_loss: 273304160.0000\n",
            "Epoch 64/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 242332336.0000 - val_loss: 247003552.0000\n",
            "Epoch 65/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236151264.0000 - val_loss: 224930560.0000\n",
            "Epoch 66/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 231055136.0000 - val_loss: 261443056.0000\n",
            "Epoch 67/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 235212608.0000 - val_loss: 256618304.0000\n",
            "Epoch 68/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 239768080.0000 - val_loss: 302821376.0000\n",
            "Epoch 69/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 239406848.0000 - val_loss: 228558096.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "jG1I_-jh7fu0",
        "outputId": "3afcc915-a5f7-40b2-9edb-ed291b7591c6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fad820e2210>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "prediction = estimator.predict(X_test)\n",
        "print(\"r_square score: \", r2_score(y_test,prediction))\n",
        "yy = np.array(y_test)\n",
        "predd = np.array(prediction)\n",
        "for i in range(10):\n",
        "  print(\"real value of y_test: \" + str(yy[i]) + \" -> the predict: \" + str(predd[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnQXNvh3-rVR",
        "outputId": "5d9120b6-2d24-4ca7-a4ca-892e4e4562b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 1ms/step\n",
            "r_square score:  0.8486160580580784\n",
            "real value of y_test: 8.220417 -> the predict: 0.02882789\n",
            "real value of y_test: 30.228708 -> the predict: 10.923758\n",
            "real value of y_test: 50.468163 -> the predict: 343.02524\n",
            "real value of y_test: 99999.0 -> the predict: 92324.414\n",
            "real value of y_test: 77.675598 -> the predict: 18.015327\n",
            "real value of y_test: 29.797169 -> the predict: 10.94411\n",
            "real value of y_test: 53.971336 -> the predict: 14.690141\n",
            "real value of y_test: 7.049716 -> the predict: 22.179386\n",
            "real value of y_test: 99999.0 -> the predict: 90667.734\n",
            "real value of y_test: 2.514874 -> the predict: 3.4916024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "print(\"RMSE:\")\n",
        "sqrt(mean_squared_error(yy, predd)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSyzIFK5uzHP",
        "outputId": "e2f0b14b-f84b-43f5-8c3a-39e796182955"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14718.849618799999"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}