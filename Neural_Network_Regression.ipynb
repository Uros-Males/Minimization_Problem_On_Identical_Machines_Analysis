{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLXql92ebQIAKmbxNMfGJ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uros-Males/Minimization_Problem_On_Identical_Machines_Analysis/blob/main/Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YiQcuNkDxHUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5dba561-83cd-41e8-f72d-2b15d7aff49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8750\n"
          ]
        }
      ],
      "source": [
        "#IN PROGRESS....\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import time\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/C-instances-runtime-analysis.csv')\n",
        "print(df.shape[0])\n",
        "\n",
        "shuffled = df.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = ['y', 'index', 'inst.name','type', 'CPLEXStatus']\n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_modified = X.drop(['class','m','subtype', '(n/m)^3', '(m/n)^3', '(m/n)^2'], axis=1)\n",
        "#X_modified = X.drop(['max', 'n/m', '(n/m)^2', '(n/m)^3', 'm/n', '(m/n)^2', '(m/n)^3', 'class', 'av.length'], axis = 1)"
      ],
      "metadata": {
        "id": "Jzlk_oaRyQjm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Dropout,BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras \n",
        "\n",
        "\n",
        "def custom_activation(x):\n",
        "    #return K.relu(tensorflow.subtract(x,-1)) - K.relu(tensorflow.subtract(x,1))\n",
        "    return 99999*1/(1+K.exp(-x))\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(8, input_dim=X_modified.shape[1], activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "\n",
        "    #classifier.add(Dense(32, activation = 'relu'))\n",
        "    #classifier.add(Dense(32, activation = 'relu'))\n",
        "    #classifier.add(Dense(16, activation = 'relu'))\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    \n",
        "    model.add(Dense(1, activation = custom_activation))\n",
        "    #model.add(Activation(custom_activation, name='SpecialActivation'))\n",
        "    model.compile(loss='mean_squared_error', optimizer=tensorflow.keras.optimizers.Adam(clipnorm=1))\n",
        "    #model.compile(loss='mean_squared_error', optimizer='RMSProp')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7_m2qFDRya94"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc2 = StandardScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y, random_state=0, train_size = 0.8)\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#y_train = sc2.fit_transform(y_train.values.reshape(-1,1))\n",
        "#y_test = sc2.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "estimator = KerasRegressor(build_fn=make_model, epochs=800, batch_size=128, verbose=1)\n",
        "\n",
        "#history=estimator.fit(X_train,y_train)\n",
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 50, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = estimator.fit(X_train, y_train, validation_data =(X_test, y_test), \n",
        "                    callbacks =[earlystopping])\n",
        "#plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JHin8gI5ftQ",
        "outputId": "8841e6a9-c0e0-47f4-da8a-c0227d9d13cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 2s 11ms/step - loss: 1615273216.0000 - val_loss: 781666368.0000\n",
            "Epoch 2/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 457879008.0000 - val_loss: 423019744.0000\n",
            "Epoch 3/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 304391776.0000 - val_loss: 333174432.0000\n",
            "Epoch 4/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 277503776.0000 - val_loss: 312082784.0000\n",
            "Epoch 5/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 257582384.0000 - val_loss: 295732608.0000\n",
            "Epoch 6/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 258326496.0000 - val_loss: 281272864.0000\n",
            "Epoch 7/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 244326704.0000 - val_loss: 282822208.0000\n",
            "Epoch 8/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 238433824.0000 - val_loss: 262374448.0000\n",
            "Epoch 9/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 240295680.0000 - val_loss: 255184400.0000\n",
            "Epoch 10/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 241489360.0000 - val_loss: 284203648.0000\n",
            "Epoch 11/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 226913632.0000 - val_loss: 255655360.0000\n",
            "Epoch 12/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 227747200.0000 - val_loss: 245697408.0000\n",
            "Epoch 13/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 225161008.0000 - val_loss: 230597744.0000\n",
            "Epoch 14/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 222021376.0000 - val_loss: 231936272.0000\n",
            "Epoch 15/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 225217968.0000 - val_loss: 226740736.0000\n",
            "Epoch 16/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 217425024.0000 - val_loss: 228223488.0000\n",
            "Epoch 17/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 217585168.0000 - val_loss: 225138992.0000\n",
            "Epoch 18/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 219420880.0000 - val_loss: 241649392.0000\n",
            "Epoch 19/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 218073776.0000 - val_loss: 222698624.0000\n",
            "Epoch 20/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 212620704.0000 - val_loss: 223745264.0000\n",
            "Epoch 21/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 211414768.0000 - val_loss: 243202640.0000\n",
            "Epoch 22/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 220550560.0000 - val_loss: 230196400.0000\n",
            "Epoch 23/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 211858688.0000 - val_loss: 227369856.0000\n",
            "Epoch 24/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 214244992.0000 - val_loss: 215964832.0000\n",
            "Epoch 25/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 211130800.0000 - val_loss: 224940816.0000\n",
            "Epoch 26/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 208178592.0000 - val_loss: 224107792.0000\n",
            "Epoch 27/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 209083936.0000 - val_loss: 222140080.0000\n",
            "Epoch 28/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 211332784.0000 - val_loss: 218389856.0000\n",
            "Epoch 29/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 210373504.0000 - val_loss: 212401472.0000\n",
            "Epoch 30/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 207415616.0000 - val_loss: 237856848.0000\n",
            "Epoch 31/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 212752704.0000 - val_loss: 220794368.0000\n",
            "Epoch 32/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 208200064.0000 - val_loss: 240686832.0000\n",
            "Epoch 33/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 211244656.0000 - val_loss: 222875824.0000\n",
            "Epoch 34/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 214841936.0000 - val_loss: 222847680.0000\n",
            "Epoch 35/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 206795840.0000 - val_loss: 232007968.0000\n",
            "Epoch 36/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 206754576.0000 - val_loss: 211551424.0000\n",
            "Epoch 37/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 207381984.0000 - val_loss: 216723040.0000\n",
            "Epoch 38/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 208867088.0000 - val_loss: 220469680.0000\n",
            "Epoch 39/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 209381616.0000 - val_loss: 223613536.0000\n",
            "Epoch 40/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 207458784.0000 - val_loss: 222942768.0000\n",
            "Epoch 41/800\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 206710896.0000 - val_loss: 229371344.0000\n",
            "Epoch 42/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 210645280.0000 - val_loss: 221522864.0000\n",
            "Epoch 43/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 201629888.0000 - val_loss: 234474704.0000\n",
            "Epoch 44/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 210330656.0000 - val_loss: 214883344.0000\n",
            "Epoch 45/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 205960992.0000 - val_loss: 219736736.0000\n",
            "Epoch 46/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 203652976.0000 - val_loss: 225543392.0000\n",
            "Epoch 47/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 208756352.0000 - val_loss: 214556272.0000\n",
            "Epoch 48/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 200468976.0000 - val_loss: 221723120.0000\n",
            "Epoch 49/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 209263968.0000 - val_loss: 214166128.0000\n",
            "Epoch 50/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 208927024.0000 - val_loss: 245667088.0000\n",
            "Epoch 51/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 212410416.0000 - val_loss: 218742096.0000\n",
            "Epoch 52/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 200820256.0000 - val_loss: 216317392.0000\n",
            "Epoch 53/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 202692304.0000 - val_loss: 221381792.0000\n",
            "Epoch 54/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 202710720.0000 - val_loss: 217712928.0000\n",
            "Epoch 55/800\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 206780416.0000 - val_loss: 212469184.0000\n",
            "Epoch 56/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 206636960.0000 - val_loss: 215350848.0000\n",
            "Epoch 57/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 202687376.0000 - val_loss: 214815328.0000\n",
            "Epoch 58/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 203102864.0000 - val_loss: 215887008.0000\n",
            "Epoch 59/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 208811136.0000 - val_loss: 240841312.0000\n",
            "Epoch 60/800\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 207084592.0000 - val_loss: 210700096.0000\n",
            "Epoch 61/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 201613632.0000 - val_loss: 231527472.0000\n",
            "Epoch 62/800\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 205437680.0000 - val_loss: 212660464.0000\n",
            "Epoch 63/800\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 202393024.0000 - val_loss: 213974240.0000\n",
            "Epoch 64/800\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 203238272.0000 - val_loss: 216291552.0000\n",
            "Epoch 65/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 200785136.0000 - val_loss: 216012528.0000\n",
            "Epoch 66/800\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 197883088.0000 - val_loss: 219543600.0000\n",
            "Epoch 67/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 199630704.0000 - val_loss: 220055888.0000\n",
            "Epoch 68/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 203992768.0000 - val_loss: 215015584.0000\n",
            "Epoch 69/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 200524896.0000 - val_loss: 223587472.0000\n",
            "Epoch 70/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 198124384.0000 - val_loss: 219053392.0000\n",
            "Epoch 71/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 198387296.0000 - val_loss: 217786880.0000\n",
            "Epoch 72/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 197125424.0000 - val_loss: 215067184.0000\n",
            "Epoch 73/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 204115584.0000 - val_loss: 216161104.0000\n",
            "Epoch 74/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 199457312.0000 - val_loss: 220064464.0000\n",
            "Epoch 75/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 202455952.0000 - val_loss: 217769376.0000\n",
            "Epoch 76/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 201642240.0000 - val_loss: 232150848.0000\n",
            "Epoch 77/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 202453536.0000 - val_loss: 221236800.0000\n",
            "Epoch 78/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 199479168.0000 - val_loss: 217277136.0000\n",
            "Epoch 79/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 200703808.0000 - val_loss: 216908096.0000\n",
            "Epoch 80/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 195402512.0000 - val_loss: 212939200.0000\n",
            "Epoch 81/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 200278112.0000 - val_loss: 215650512.0000\n",
            "Epoch 82/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 197488976.0000 - val_loss: 223452064.0000\n",
            "Epoch 83/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 199516560.0000 - val_loss: 219319184.0000\n",
            "Epoch 84/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 197149584.0000 - val_loss: 214089632.0000\n",
            "Epoch 85/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 197078320.0000 - val_loss: 231759152.0000\n",
            "Epoch 86/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 198052656.0000 - val_loss: 215445312.0000\n",
            "Epoch 87/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 195259472.0000 - val_loss: 220961456.0000\n",
            "Epoch 88/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 201209920.0000 - val_loss: 259542432.0000\n",
            "Epoch 89/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 206807104.0000 - val_loss: 214630160.0000\n",
            "Epoch 90/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 194598848.0000 - val_loss: 224116528.0000\n",
            "Epoch 91/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 203634416.0000 - val_loss: 217296048.0000\n",
            "Epoch 92/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 196888800.0000 - val_loss: 212392752.0000\n",
            "Epoch 93/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 201765632.0000 - val_loss: 216724976.0000\n",
            "Epoch 94/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 195308512.0000 - val_loss: 208352096.0000\n",
            "Epoch 95/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 193009536.0000 - val_loss: 223304896.0000\n",
            "Epoch 96/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 193999008.0000 - val_loss: 214018288.0000\n",
            "Epoch 97/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 195919424.0000 - val_loss: 220310784.0000\n",
            "Epoch 98/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 194785744.0000 - val_loss: 216417600.0000\n",
            "Epoch 99/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 192926144.0000 - val_loss: 219570528.0000\n",
            "Epoch 100/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 193899168.0000 - val_loss: 229657152.0000\n",
            "Epoch 101/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 195631744.0000 - val_loss: 225044352.0000\n",
            "Epoch 102/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 200007312.0000 - val_loss: 224531824.0000\n",
            "Epoch 103/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 197413488.0000 - val_loss: 219368160.0000\n",
            "Epoch 104/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 193061168.0000 - val_loss: 215982800.0000\n",
            "Epoch 105/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 196127600.0000 - val_loss: 210732080.0000\n",
            "Epoch 106/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 195890656.0000 - val_loss: 219595216.0000\n",
            "Epoch 107/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 195605408.0000 - val_loss: 215897136.0000\n",
            "Epoch 108/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 192480816.0000 - val_loss: 219348480.0000\n",
            "Epoch 109/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 195369296.0000 - val_loss: 212638240.0000\n",
            "Epoch 110/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 193682048.0000 - val_loss: 241134848.0000\n",
            "Epoch 111/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 192308656.0000 - val_loss: 227705952.0000\n",
            "Epoch 112/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 190225840.0000 - val_loss: 219677488.0000\n",
            "Epoch 113/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 192073616.0000 - val_loss: 219132704.0000\n",
            "Epoch 114/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 189697440.0000 - val_loss: 219778032.0000\n",
            "Epoch 115/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 195158336.0000 - val_loss: 215591552.0000\n",
            "Epoch 116/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 190083360.0000 - val_loss: 218344704.0000\n",
            "Epoch 117/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 190770800.0000 - val_loss: 213849392.0000\n",
            "Epoch 118/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 193554848.0000 - val_loss: 213481984.0000\n",
            "Epoch 119/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 191393200.0000 - val_loss: 218936080.0000\n",
            "Epoch 120/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 186271776.0000 - val_loss: 227412752.0000\n",
            "Epoch 121/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 190088464.0000 - val_loss: 219492752.0000\n",
            "Epoch 122/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 192383552.0000 - val_loss: 222794288.0000\n",
            "Epoch 123/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 186159648.0000 - val_loss: 212932832.0000\n",
            "Epoch 124/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 190635744.0000 - val_loss: 219325008.0000\n",
            "Epoch 125/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 190235728.0000 - val_loss: 218771440.0000\n",
            "Epoch 126/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 187226752.0000 - val_loss: 217785072.0000\n",
            "Epoch 127/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 186325472.0000 - val_loss: 225662400.0000\n",
            "Epoch 128/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 192416960.0000 - val_loss: 217048240.0000\n",
            "Epoch 129/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 189770416.0000 - val_loss: 216362128.0000\n",
            "Epoch 130/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 187875472.0000 - val_loss: 219095008.0000\n",
            "Epoch 131/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 192976736.0000 - val_loss: 247046704.0000\n",
            "Epoch 132/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 196501200.0000 - val_loss: 219532224.0000\n",
            "Epoch 133/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 187093472.0000 - val_loss: 223093488.0000\n",
            "Epoch 134/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 187033184.0000 - val_loss: 222116368.0000\n",
            "Epoch 135/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 185317344.0000 - val_loss: 224016192.0000\n",
            "Epoch 136/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 192700832.0000 - val_loss: 222844736.0000\n",
            "Epoch 137/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 188377408.0000 - val_loss: 219821840.0000\n",
            "Epoch 138/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 189070464.0000 - val_loss: 220764640.0000\n",
            "Epoch 139/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 190182400.0000 - val_loss: 221580432.0000\n",
            "Epoch 140/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 186635376.0000 - val_loss: 216064048.0000\n",
            "Epoch 141/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 185980640.0000 - val_loss: 221055856.0000\n",
            "Epoch 142/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 185562512.0000 - val_loss: 217272640.0000\n",
            "Epoch 143/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 185732416.0000 - val_loss: 218870928.0000\n",
            "Epoch 144/800\n",
            "55/55 [==============================] - 0s 3ms/step - loss: 182998880.0000 - val_loss: 222902272.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "jG1I_-jh7fu0",
        "outputId": "c4012a19-1ff5-48bf-ea3c-b7737722e40b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f80c8879a50>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "prediction = estimator.predict(X_test)\n",
        "print(\"r_square score: \", r2_score(y_test,prediction))\n",
        "#y_test = sc2.inverse_transform(y_test.reshape(-1,1))\n",
        "yy = np.array(y_test)\n",
        "#prediction = sc2.inverse_transform(prediction.reshape(-1,1))\n",
        "predd = np.array(prediction)\n",
        "for i in range(len(yy)):\n",
        "  if(yy[i]-predd[i] > 99000):\n",
        "    print(\"real value of y_test: \" + str(yy[i]) + \" -> the predict: \" + str(predd[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnQXNvh3-rVR",
        "outputId": "17c3eaee-6b0c-4c73-95ab-66dc59a69972"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 1ms/step\n",
            "r_square score:  0.8451117707998042\n",
            "real value of y_test: 99999.0 -> the predict: 0.5673276\n",
            "real value of y_test: 99999.0 -> the predict: 52.352562\n",
            "real value of y_test: 99999.0 -> the predict: 66.75517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "print(\"RMSE:\")\n",
        "sqrt(mean_squared_error(yy, predd)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSyzIFK5uzHP",
        "outputId": "6bc398fe-5b54-4419-ae1e-96cac930fd8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14434.406235086677"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}