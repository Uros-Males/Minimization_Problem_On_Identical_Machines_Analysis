{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWPjn5WmbG2K2qRUnYHlJP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uros-Males/Minimization_Problem_On_Identical_Machines_Analysis/blob/main/Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YiQcuNkDxHUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fd3343-3f9d-457e-9a06-0ce216b33bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8750\n"
          ]
        }
      ],
      "source": [
        "#IN PROGRESS....\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import time\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/C-instances-runtime-analysis.csv')\n",
        "print(df.shape[0])\n",
        "\n",
        "shuffled = df.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = ['y', 'index', 'inst.name','type', 'CPLEXStatus']\n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_modified = X\n",
        "X_modified = X.drop(['max', 'n/m', '(n/m)^2', '(n/m)^3', 'm/n', '(m/n)^2', '(m/n)^3', 'class', 'av.length'], axis = 1)"
      ],
      "metadata": {
        "id": "Jzlk_oaRyQjm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Dropout,BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras \n",
        "\n",
        "\n",
        "def custom_activation(x):\n",
        "    return 99999*1/(1+K.exp(-x))\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(8, input_dim=X_modified.shape[1], activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    \n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    #model.add(Dropout(0.15))\n",
        "    \n",
        "    model.add(Dense(4, activation='relu'))\n",
        "    \n",
        "    model.add(Dense(1, activation = custom_activation))\n",
        "    #model.add(Activation(custom_activation, name='SpecialActivation'))\n",
        "    model.compile(loss='mean_squared_error', optimizer=tensorflow.keras.optimizers.Adam(clipnorm=1))\n",
        "    return model"
      ],
      "metadata": {
        "id": "7_m2qFDRya94"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler =  MinMaxScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y, random_state=0, train_size = 0.83)\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "estimator = KerasRegressor(build_fn=make_model, epochs=300, batch_size=32, verbose=1)\n",
        "\n",
        "#history=estimator.fit(X_train,y_train)\n",
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 25, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = estimator.fit(X_train, y_train, validation_data =(X_test, y_test), \n",
        "                    callbacks =[earlystopping])\n",
        "#plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JHin8gI5ftQ",
        "outputId": "cabaa301-851a-4566-b6f7-77340e5aad96"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "227/227 [==============================] - 3s 7ms/step - loss: 1481875328.0000 - val_loss: 745845568.0000\n",
            "Epoch 2/300\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 492110272.0000 - val_loss: 437689088.0000\n",
            "Epoch 3/300\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 357655776.0000 - val_loss: 391075392.0000\n",
            "Epoch 4/300\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 321575136.0000 - val_loss: 382319904.0000\n",
            "Epoch 5/300\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 302516896.0000 - val_loss: 357339328.0000\n",
            "Epoch 6/300\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 291326432.0000 - val_loss: 329542944.0000\n",
            "Epoch 7/300\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 291277184.0000 - val_loss: 330098240.0000\n",
            "Epoch 8/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 286747072.0000 - val_loss: 349596992.0000\n",
            "Epoch 9/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 287618624.0000 - val_loss: 319702944.0000\n",
            "Epoch 10/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 282272064.0000 - val_loss: 312507808.0000\n",
            "Epoch 11/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 278008160.0000 - val_loss: 340278912.0000\n",
            "Epoch 12/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 272249472.0000 - val_loss: 293204832.0000\n",
            "Epoch 13/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 269996864.0000 - val_loss: 304148768.0000\n",
            "Epoch 14/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 270643904.0000 - val_loss: 317151232.0000\n",
            "Epoch 15/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 275007552.0000 - val_loss: 284948160.0000\n",
            "Epoch 16/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 266459904.0000 - val_loss: 270025536.0000\n",
            "Epoch 17/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 257909984.0000 - val_loss: 312846784.0000\n",
            "Epoch 18/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 255786192.0000 - val_loss: 299539360.0000\n",
            "Epoch 19/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 243767744.0000 - val_loss: 283201344.0000\n",
            "Epoch 20/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 247928704.0000 - val_loss: 243004752.0000\n",
            "Epoch 21/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 241777728.0000 - val_loss: 254316816.0000\n",
            "Epoch 22/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 243874208.0000 - val_loss: 256334448.0000\n",
            "Epoch 23/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 234256336.0000 - val_loss: 239253312.0000\n",
            "Epoch 24/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 240940976.0000 - val_loss: 236833040.0000\n",
            "Epoch 25/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 233427440.0000 - val_loss: 245098080.0000\n",
            "Epoch 26/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237641056.0000 - val_loss: 234831824.0000\n",
            "Epoch 27/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 240849264.0000 - val_loss: 262519184.0000\n",
            "Epoch 28/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 244902912.0000 - val_loss: 239013696.0000\n",
            "Epoch 29/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237026080.0000 - val_loss: 224921488.0000\n",
            "Epoch 30/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 247079824.0000 - val_loss: 281916832.0000\n",
            "Epoch 31/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 238935264.0000 - val_loss: 237432784.0000\n",
            "Epoch 32/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 250234096.0000 - val_loss: 293948416.0000\n",
            "Epoch 33/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 260570992.0000 - val_loss: 275603872.0000\n",
            "Epoch 34/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237381776.0000 - val_loss: 250998160.0000\n",
            "Epoch 35/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236689168.0000 - val_loss: 227552224.0000\n",
            "Epoch 36/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 235791504.0000 - val_loss: 255536672.0000\n",
            "Epoch 37/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 235952352.0000 - val_loss: 248759776.0000\n",
            "Epoch 38/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 249567088.0000 - val_loss: 227547200.0000\n",
            "Epoch 39/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 241518176.0000 - val_loss: 218621184.0000\n",
            "Epoch 40/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 233345984.0000 - val_loss: 235250544.0000\n",
            "Epoch 41/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 242992688.0000 - val_loss: 223759520.0000\n",
            "Epoch 42/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 235944400.0000 - val_loss: 232650624.0000\n",
            "Epoch 43/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 239388832.0000 - val_loss: 231115904.0000\n",
            "Epoch 44/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 242623024.0000 - val_loss: 228642112.0000\n",
            "Epoch 45/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 247802976.0000 - val_loss: 251133584.0000\n",
            "Epoch 46/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 240733344.0000 - val_loss: 242397088.0000\n",
            "Epoch 47/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 243775936.0000 - val_loss: 218053152.0000\n",
            "Epoch 48/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236967088.0000 - val_loss: 238390768.0000\n",
            "Epoch 49/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 242487440.0000 - val_loss: 241908352.0000\n",
            "Epoch 50/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 240751312.0000 - val_loss: 259925424.0000\n",
            "Epoch 51/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237701440.0000 - val_loss: 329422880.0000\n",
            "Epoch 52/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 248875424.0000 - val_loss: 235072496.0000\n",
            "Epoch 53/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236291328.0000 - val_loss: 290953408.0000\n",
            "Epoch 54/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 241462416.0000 - val_loss: 223357264.0000\n",
            "Epoch 55/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 230840928.0000 - val_loss: 237403504.0000\n",
            "Epoch 56/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 239437760.0000 - val_loss: 240344336.0000\n",
            "Epoch 57/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 250166048.0000 - val_loss: 231012064.0000\n",
            "Epoch 58/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 255004560.0000 - val_loss: 231248736.0000\n",
            "Epoch 59/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 228631904.0000 - val_loss: 219641984.0000\n",
            "Epoch 60/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 242525776.0000 - val_loss: 259083600.0000\n",
            "Epoch 61/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 233951488.0000 - val_loss: 239171184.0000\n",
            "Epoch 62/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237595152.0000 - val_loss: 335552064.0000\n",
            "Epoch 63/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 244445648.0000 - val_loss: 289756512.0000\n",
            "Epoch 64/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237402480.0000 - val_loss: 268828672.0000\n",
            "Epoch 65/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 241180848.0000 - val_loss: 232932480.0000\n",
            "Epoch 66/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 238663744.0000 - val_loss: 213826368.0000\n",
            "Epoch 67/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 234966992.0000 - val_loss: 220651984.0000\n",
            "Epoch 68/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 245616928.0000 - val_loss: 235072880.0000\n",
            "Epoch 69/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 239631696.0000 - val_loss: 260047648.0000\n",
            "Epoch 70/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237238016.0000 - val_loss: 229433712.0000\n",
            "Epoch 71/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 246666976.0000 - val_loss: 280541120.0000\n",
            "Epoch 72/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237082208.0000 - val_loss: 234133744.0000\n",
            "Epoch 73/300\n",
            "227/227 [==============================] - 0s 2ms/step - loss: 239839408.0000 - val_loss: 249906224.0000\n",
            "Epoch 74/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 240380496.0000 - val_loss: 231064544.0000\n",
            "Epoch 75/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 233782736.0000 - val_loss: 276214400.0000\n",
            "Epoch 76/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235414784.0000 - val_loss: 223916032.0000\n",
            "Epoch 77/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 239706208.0000 - val_loss: 216974704.0000\n",
            "Epoch 78/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 231338864.0000 - val_loss: 241830432.0000\n",
            "Epoch 79/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 241155280.0000 - val_loss: 222342624.0000\n",
            "Epoch 80/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236605408.0000 - val_loss: 230512368.0000\n",
            "Epoch 81/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 235310240.0000 - val_loss: 224937168.0000\n",
            "Epoch 82/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236323520.0000 - val_loss: 224443120.0000\n",
            "Epoch 83/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 241185456.0000 - val_loss: 220995696.0000\n",
            "Epoch 84/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241379104.0000 - val_loss: 218049968.0000\n",
            "Epoch 85/300\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 234695792.0000 - val_loss: 228814720.0000\n",
            "Epoch 86/300\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 241248256.0000 - val_loss: 218032112.0000\n",
            "Epoch 87/300\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 242541856.0000 - val_loss: 250111552.0000\n",
            "Epoch 88/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 236423616.0000 - val_loss: 218462608.0000\n",
            "Epoch 89/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 239258976.0000 - val_loss: 226114336.0000\n",
            "Epoch 90/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 237400272.0000 - val_loss: 225172528.0000\n",
            "Epoch 91/300\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 234107312.0000 - val_loss: 232944800.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "jG1I_-jh7fu0",
        "outputId": "3f743595-17cb-418d-f728-77edb79eb9ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4f0ea55f90>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "prediction = estimator.predict(X_test)\n",
        "print(\"r_square score: \", r2_score(y_test,prediction))\n",
        "yy = np.array(y_test)\n",
        "predd = np.array(prediction)\n",
        "for i in range(10):\n",
        "  print(\"real value of y_test: \" + str(yy[i]) + \" -> the predict: \" + str(predd[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnQXNvh3-rVR",
        "outputId": "7f2aaaf7-8330-482b-ca14-820a15ec0efd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 1ms/step\n",
            "r_square score:  0.8447864611381928\n",
            "real value of y_test: 34.84095 -> the predict: 0.04818043\n",
            "real value of y_test: 430.069794 -> the predict: 2.0037694\n",
            "real value of y_test: 141.699677 -> the predict: 1.9049865\n",
            "real value of y_test: 7.439738 -> the predict: 0.032969143\n",
            "real value of y_test: 25.334997 -> the predict: 0.0006766373\n",
            "real value of y_test: 318.094604 -> the predict: 1.4119083\n",
            "real value of y_test: 0.090652 -> the predict: 0.07541133\n",
            "real value of y_test: 52.323692 -> the predict: 5.042119e-09\n",
            "real value of y_test: 318.850769 -> the predict: 0.085426636\n",
            "real value of y_test: 0.605969 -> the predict: 0.009048541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "print(\"RMSE:\")\n",
        "sqrt(mean_squared_error(yy, predd)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSyzIFK5uzHP",
        "outputId": "49fcb3f0-b49e-4993-a2a3-b5666a26ad69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14622.80372188153"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}