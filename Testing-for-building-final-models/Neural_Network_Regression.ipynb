{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmBSGPobNekWmh+wf8gUft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uros-Males/Minimization_Problem_On_Identical_Machines_Analysis/blob/main/Neural_Network_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YiQcuNkDxHUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d098c8-3056-4ab9-ef7e-14671381d445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8750\n"
          ]
        }
      ],
      "source": [
        "#IN PROGRESS....\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import time\n",
        "\n",
        "df = pd.read_csv('/content/sample_data/C-instances-runtime-analysis.csv')\n",
        "print(df.shape[0])\n",
        "\n",
        "shuffled = df.sample(frac=1).reset_index()\n",
        "\n",
        "columns_dont_want = ['y', 'index', 'inst.name','type', 'CPLEXStatus']\n",
        "select = [x for x in shuffled.columns if x not in columns_dont_want]\n",
        "\n",
        "X = shuffled.loc[:, select]\n",
        "\n",
        "y = shuffled.loc[:,'y']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_modified = X.drop(['n/m', 'min','indeks', 'class',  'subtype', '(m/n)^3', '(m/n)^2', '(n/m)^2', '(n/m)^3','m/n'], axis=1)\n",
        "print(X_modified.head())\n",
        "#X_modified = X.drop(['max', 'n/m', '(n/m)^2', '(n/m)^3', 'm/n', '(m/n)^2', '(m/n)^3', 'class', 'av.length'], axis = 1)"
      ],
      "metadata": {
        "id": "Jzlk_oaRyQjm",
        "outputId": "50a3e235-7553-43e4-b1a0-3c3de561fd3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     n   m   av.length     std.dev  median  range  max    k\n",
            "0  160  40  390.706238  129.514984   381.5    479  639  138\n",
            "1  144  32   99.159721   17.970320   101.5     94  140   62\n",
            "2   60  24  221.233337   61.493938   227.5    256  349   50\n",
            "3  200  20   49.150002   28.459570    50.0     99  100   88\n",
            "4  126  28  311.658722  108.548103   306.5    367  496  111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense ,Dropout,BatchNormalization\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow import keras \n",
        "\n",
        "\n",
        "def custom_activation(x):\n",
        "    #return K.relu(tensorflow.subtract(x,-1)) - K.relu(tensorflow.subtract(x,1))\n",
        "    return 99999*1/(1+K.exp(-x))\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "def make_model():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Dense(8, input_dim=X_modified.shape[1], activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Dense(16, activation = 'relu'))\n",
        "\n",
        "    #classifier.add(Dense(32, activation = 'relu'))\n",
        "    #classifier.add(Dense(32, activation = 'relu'))\n",
        "    #classifier.add(Dense(16, activation = 'relu'))\n",
        "\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    \n",
        "    model.add(Dense(1, activation = custom_activation))\n",
        "    #model.add(Activation(custom_activation, name='SpecialActivation'))\n",
        "    model.compile(loss='mean_squared_error', optimizer=tensorflow.keras.optimizers.Adam(clipnorm=1))\n",
        "    #model.compile(loss='mean_squared_error', optimizer='RMSProp')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "7_m2qFDRya94"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc2 = StandardScaler()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_modified, y, random_state=0, train_size = 0.83)\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#y_train = sc2.fit_transform(y_train.values.reshape(-1,1))\n",
        "#y_test = sc2.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "estimator = KerasRegressor(build_fn=make_model, epochs=800, batch_size=32, verbose=1)\n",
        "\n",
        "#history=estimator.fit(X_train,y_train)\n",
        "from keras.metrics import accuracy\n",
        "from keras import callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 50, \n",
        "                                        restore_best_weights = True)\n",
        "  \n",
        "history = estimator.fit(X_train, y_train, validation_data =(X_test, y_test), \n",
        "                    callbacks =[earlystopping])\n",
        "#plt.plot(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JHin8gI5ftQ",
        "outputId": "047eed40-37f2-4da0-9ff9-65a7cca8470f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "227/227 [==============================] - 3s 7ms/step - loss: 697820800.0000 - val_loss: 313723680.0000\n",
            "Epoch 2/800\n",
            "227/227 [==============================] - 1s 7ms/step - loss: 310719232.0000 - val_loss: 258650560.0000\n",
            "Epoch 3/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 289108256.0000 - val_loss: 249628384.0000\n",
            "Epoch 4/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 289826016.0000 - val_loss: 247196048.0000\n",
            "Epoch 5/800\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 295210368.0000 - val_loss: 304738016.0000\n",
            "Epoch 6/800\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 285997248.0000 - val_loss: 267979456.0000\n",
            "Epoch 7/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 294930304.0000 - val_loss: 220679488.0000\n",
            "Epoch 8/800\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 277854976.0000 - val_loss: 238978912.0000\n",
            "Epoch 9/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 289680160.0000 - val_loss: 241519312.0000\n",
            "Epoch 10/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 264655904.0000 - val_loss: 213608864.0000\n",
            "Epoch 11/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 268069408.0000 - val_loss: 202042064.0000\n",
            "Epoch 12/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 264966032.0000 - val_loss: 210099600.0000\n",
            "Epoch 13/800\n",
            "227/227 [==============================] - 1s 7ms/step - loss: 264701904.0000 - val_loss: 223052784.0000\n",
            "Epoch 14/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 267240000.0000 - val_loss: 208450352.0000\n",
            "Epoch 15/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 260314448.0000 - val_loss: 220034384.0000\n",
            "Epoch 16/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 263070384.0000 - val_loss: 220632496.0000\n",
            "Epoch 17/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 263859648.0000 - val_loss: 213110720.0000\n",
            "Epoch 18/800\n",
            "227/227 [==============================] - 2s 7ms/step - loss: 252106416.0000 - val_loss: 215176528.0000\n",
            "Epoch 19/800\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 259167344.0000 - val_loss: 204835344.0000\n",
            "Epoch 20/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 266315936.0000 - val_loss: 223339856.0000\n",
            "Epoch 21/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 264247360.0000 - val_loss: 217429744.0000\n",
            "Epoch 22/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 259984448.0000 - val_loss: 229131600.0000\n",
            "Epoch 23/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 258632080.0000 - val_loss: 236514560.0000\n",
            "Epoch 24/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 256149792.0000 - val_loss: 202933696.0000\n",
            "Epoch 25/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 250827216.0000 - val_loss: 217240384.0000\n",
            "Epoch 26/800\n",
            "227/227 [==============================] - 1s 2ms/step - loss: 253420720.0000 - val_loss: 202685520.0000\n",
            "Epoch 27/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 258382912.0000 - val_loss: 258690736.0000\n",
            "Epoch 28/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 256390112.0000 - val_loss: 179002416.0000\n",
            "Epoch 29/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 248171840.0000 - val_loss: 192164032.0000\n",
            "Epoch 30/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 251783296.0000 - val_loss: 190867744.0000\n",
            "Epoch 31/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 247915984.0000 - val_loss: 205162048.0000\n",
            "Epoch 32/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241699808.0000 - val_loss: 199232112.0000\n",
            "Epoch 33/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 253717856.0000 - val_loss: 194356672.0000\n",
            "Epoch 34/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 251376208.0000 - val_loss: 245521264.0000\n",
            "Epoch 35/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 256386384.0000 - val_loss: 188552992.0000\n",
            "Epoch 36/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 240292592.0000 - val_loss: 200708112.0000\n",
            "Epoch 37/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 252507568.0000 - val_loss: 219034016.0000\n",
            "Epoch 38/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 249343952.0000 - val_loss: 190207808.0000\n",
            "Epoch 39/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241957232.0000 - val_loss: 211982640.0000\n",
            "Epoch 40/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 254255056.0000 - val_loss: 192270688.0000\n",
            "Epoch 41/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235172960.0000 - val_loss: 214035856.0000\n",
            "Epoch 42/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 248221856.0000 - val_loss: 202543904.0000\n",
            "Epoch 43/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 246039360.0000 - val_loss: 218638288.0000\n",
            "Epoch 44/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 245110192.0000 - val_loss: 196377568.0000\n",
            "Epoch 45/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241775472.0000 - val_loss: 186743296.0000\n",
            "Epoch 46/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 253255360.0000 - val_loss: 172189792.0000\n",
            "Epoch 47/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238086976.0000 - val_loss: 189545856.0000\n",
            "Epoch 48/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239873936.0000 - val_loss: 201182576.0000\n",
            "Epoch 49/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 244343040.0000 - val_loss: 189176448.0000\n",
            "Epoch 50/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239223920.0000 - val_loss: 180995616.0000\n",
            "Epoch 51/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 248482208.0000 - val_loss: 197237104.0000\n",
            "Epoch 52/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 229970432.0000 - val_loss: 187657200.0000\n",
            "Epoch 53/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 244668880.0000 - val_loss: 200111952.0000\n",
            "Epoch 54/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 246068480.0000 - val_loss: 182979360.0000\n",
            "Epoch 55/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235405200.0000 - val_loss: 186597488.0000\n",
            "Epoch 56/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235986928.0000 - val_loss: 185409664.0000\n",
            "Epoch 57/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239248880.0000 - val_loss: 197488464.0000\n",
            "Epoch 58/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236076368.0000 - val_loss: 215474928.0000\n",
            "Epoch 59/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 248193632.0000 - val_loss: 208437424.0000\n",
            "Epoch 60/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 240160160.0000 - val_loss: 180281616.0000\n",
            "Epoch 61/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 233694208.0000 - val_loss: 180305616.0000\n",
            "Epoch 62/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 243841264.0000 - val_loss: 195930560.0000\n",
            "Epoch 63/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241051136.0000 - val_loss: 188837952.0000\n",
            "Epoch 64/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 242324160.0000 - val_loss: 218850912.0000\n",
            "Epoch 65/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 233918928.0000 - val_loss: 222519952.0000\n",
            "Epoch 66/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 248039824.0000 - val_loss: 189778912.0000\n",
            "Epoch 67/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237877408.0000 - val_loss: 178963328.0000\n",
            "Epoch 68/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 254274064.0000 - val_loss: 201390560.0000\n",
            "Epoch 69/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241687872.0000 - val_loss: 194927696.0000\n",
            "Epoch 70/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 244677232.0000 - val_loss: 172935168.0000\n",
            "Epoch 71/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 240287024.0000 - val_loss: 206619040.0000\n",
            "Epoch 72/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236923888.0000 - val_loss: 205871008.0000\n",
            "Epoch 73/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 232470160.0000 - val_loss: 182105072.0000\n",
            "Epoch 74/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237386800.0000 - val_loss: 167060832.0000\n",
            "Epoch 75/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 243872800.0000 - val_loss: 168452112.0000\n",
            "Epoch 76/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 247003856.0000 - val_loss: 168274016.0000\n",
            "Epoch 77/800\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 244721488.0000 - val_loss: 196859152.0000\n",
            "Epoch 78/800\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 241924128.0000 - val_loss: 216079280.0000\n",
            "Epoch 79/800\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 252105728.0000 - val_loss: 194325584.0000\n",
            "Epoch 80/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 244538432.0000 - val_loss: 184073120.0000\n",
            "Epoch 81/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 246085408.0000 - val_loss: 169793056.0000\n",
            "Epoch 82/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236604112.0000 - val_loss: 185145520.0000\n",
            "Epoch 83/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241496256.0000 - val_loss: 171917552.0000\n",
            "Epoch 84/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 242255328.0000 - val_loss: 192414464.0000\n",
            "Epoch 85/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239071408.0000 - val_loss: 164746944.0000\n",
            "Epoch 86/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 243112496.0000 - val_loss: 165062688.0000\n",
            "Epoch 87/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 244258912.0000 - val_loss: 192674624.0000\n",
            "Epoch 88/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 243887168.0000 - val_loss: 228859792.0000\n",
            "Epoch 89/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 244893296.0000 - val_loss: 173883152.0000\n",
            "Epoch 90/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235435568.0000 - val_loss: 199472640.0000\n",
            "Epoch 91/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 243413104.0000 - val_loss: 168888624.0000\n",
            "Epoch 92/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 233521024.0000 - val_loss: 172165424.0000\n",
            "Epoch 93/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241594976.0000 - val_loss: 196185216.0000\n",
            "Epoch 94/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 246523184.0000 - val_loss: 170040592.0000\n",
            "Epoch 95/800\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 235950848.0000 - val_loss: 189280096.0000\n",
            "Epoch 96/800\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 246940208.0000 - val_loss: 172708368.0000\n",
            "Epoch 97/800\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 248188176.0000 - val_loss: 172265664.0000\n",
            "Epoch 98/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 246555728.0000 - val_loss: 184055456.0000\n",
            "Epoch 99/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 246952480.0000 - val_loss: 194879264.0000\n",
            "Epoch 100/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236378512.0000 - val_loss: 187337232.0000\n",
            "Epoch 101/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 233106240.0000 - val_loss: 203632704.0000\n",
            "Epoch 102/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241186048.0000 - val_loss: 189614432.0000\n",
            "Epoch 103/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241881872.0000 - val_loss: 223864720.0000\n",
            "Epoch 104/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236641392.0000 - val_loss: 170194192.0000\n",
            "Epoch 105/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 242705232.0000 - val_loss: 175676992.0000\n",
            "Epoch 106/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241578480.0000 - val_loss: 208188688.0000\n",
            "Epoch 107/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 242079296.0000 - val_loss: 161086864.0000\n",
            "Epoch 108/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 240037776.0000 - val_loss: 162093584.0000\n",
            "Epoch 109/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237692400.0000 - val_loss: 187194928.0000\n",
            "Epoch 110/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239375664.0000 - val_loss: 176457744.0000\n",
            "Epoch 111/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 230500560.0000 - val_loss: 199581104.0000\n",
            "Epoch 112/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237656288.0000 - val_loss: 184312864.0000\n",
            "Epoch 113/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235391376.0000 - val_loss: 184570832.0000\n",
            "Epoch 114/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237742160.0000 - val_loss: 180372832.0000\n",
            "Epoch 115/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 242003056.0000 - val_loss: 181770912.0000\n",
            "Epoch 116/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237522256.0000 - val_loss: 179572544.0000\n",
            "Epoch 117/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 231733856.0000 - val_loss: 177258928.0000\n",
            "Epoch 118/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 240000848.0000 - val_loss: 157882848.0000\n",
            "Epoch 119/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238646768.0000 - val_loss: 167309824.0000\n",
            "Epoch 120/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 230034368.0000 - val_loss: 168415888.0000\n",
            "Epoch 121/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 243207744.0000 - val_loss: 177116976.0000\n",
            "Epoch 122/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 244473664.0000 - val_loss: 168268768.0000\n",
            "Epoch 123/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239786528.0000 - val_loss: 162009872.0000\n",
            "Epoch 124/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238832160.0000 - val_loss: 182813648.0000\n",
            "Epoch 125/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 246814768.0000 - val_loss: 198459104.0000\n",
            "Epoch 126/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235136720.0000 - val_loss: 175029728.0000\n",
            "Epoch 127/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 233369168.0000 - val_loss: 175285760.0000\n",
            "Epoch 128/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 240667616.0000 - val_loss: 202518304.0000\n",
            "Epoch 129/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 233565984.0000 - val_loss: 176465344.0000\n",
            "Epoch 130/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 240042448.0000 - val_loss: 175090480.0000\n",
            "Epoch 131/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 245259344.0000 - val_loss: 176757024.0000\n",
            "Epoch 132/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239539376.0000 - val_loss: 168619920.0000\n",
            "Epoch 133/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 227241584.0000 - val_loss: 178290320.0000\n",
            "Epoch 134/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239751408.0000 - val_loss: 183344688.0000\n",
            "Epoch 135/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241271760.0000 - val_loss: 171007904.0000\n",
            "Epoch 136/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237770160.0000 - val_loss: 189517536.0000\n",
            "Epoch 137/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236129472.0000 - val_loss: 183044288.0000\n",
            "Epoch 138/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235021344.0000 - val_loss: 186099184.0000\n",
            "Epoch 139/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236440784.0000 - val_loss: 157269824.0000\n",
            "Epoch 140/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237905024.0000 - val_loss: 184538960.0000\n",
            "Epoch 141/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 234778048.0000 - val_loss: 176723232.0000\n",
            "Epoch 142/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 234331216.0000 - val_loss: 182959648.0000\n",
            "Epoch 143/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 234994528.0000 - val_loss: 189550048.0000\n",
            "Epoch 144/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236843488.0000 - val_loss: 163730336.0000\n",
            "Epoch 145/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235261328.0000 - val_loss: 176095072.0000\n",
            "Epoch 146/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241926224.0000 - val_loss: 186923712.0000\n",
            "Epoch 147/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 232554976.0000 - val_loss: 197128816.0000\n",
            "Epoch 148/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239050096.0000 - val_loss: 225691232.0000\n",
            "Epoch 149/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241730704.0000 - val_loss: 173782080.0000\n",
            "Epoch 150/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236577760.0000 - val_loss: 164654912.0000\n",
            "Epoch 151/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235301744.0000 - val_loss: 163975360.0000\n",
            "Epoch 152/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 230646032.0000 - val_loss: 188222544.0000\n",
            "Epoch 153/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 230548928.0000 - val_loss: 167528992.0000\n",
            "Epoch 154/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235948768.0000 - val_loss: 176448224.0000\n",
            "Epoch 155/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238401760.0000 - val_loss: 211287968.0000\n",
            "Epoch 156/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 240421504.0000 - val_loss: 172336912.0000\n",
            "Epoch 157/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 232993296.0000 - val_loss: 178543984.0000\n",
            "Epoch 158/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238843680.0000 - val_loss: 158408512.0000\n",
            "Epoch 159/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238087584.0000 - val_loss: 172594704.0000\n",
            "Epoch 160/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237347056.0000 - val_loss: 163125936.0000\n",
            "Epoch 161/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 225350784.0000 - val_loss: 171935536.0000\n",
            "Epoch 162/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 232046528.0000 - val_loss: 167020960.0000\n",
            "Epoch 163/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238498272.0000 - val_loss: 199010256.0000\n",
            "Epoch 164/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235600592.0000 - val_loss: 161624960.0000\n",
            "Epoch 165/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 233847520.0000 - val_loss: 189379264.0000\n",
            "Epoch 166/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 235217616.0000 - val_loss: 158344736.0000\n",
            "Epoch 167/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 231274816.0000 - val_loss: 189562336.0000\n",
            "Epoch 168/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 243222144.0000 - val_loss: 159270720.0000\n",
            "Epoch 169/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 237334384.0000 - val_loss: 171511936.0000\n",
            "Epoch 170/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241487584.0000 - val_loss: 179160160.0000\n",
            "Epoch 171/800\n",
            "227/227 [==============================] - 1s 4ms/step - loss: 237206736.0000 - val_loss: 177378576.0000\n",
            "Epoch 172/800\n",
            "227/227 [==============================] - 1s 5ms/step - loss: 243824512.0000 - val_loss: 181300528.0000\n",
            "Epoch 173/800\n",
            "227/227 [==============================] - 1s 6ms/step - loss: 230848976.0000 - val_loss: 184587040.0000\n",
            "Epoch 174/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 241190016.0000 - val_loss: 190277184.0000\n",
            "Epoch 175/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239677840.0000 - val_loss: 185653472.0000\n",
            "Epoch 176/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238774112.0000 - val_loss: 184913632.0000\n",
            "Epoch 177/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 232633632.0000 - val_loss: 172438544.0000\n",
            "Epoch 178/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 232174064.0000 - val_loss: 177736272.0000\n",
            "Epoch 179/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 242981216.0000 - val_loss: 193356656.0000\n",
            "Epoch 180/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236704208.0000 - val_loss: 174835456.0000\n",
            "Epoch 181/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 244732608.0000 - val_loss: 196189408.0000\n",
            "Epoch 182/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239259216.0000 - val_loss: 169761424.0000\n",
            "Epoch 183/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 239402192.0000 - val_loss: 177434896.0000\n",
            "Epoch 184/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 233709184.0000 - val_loss: 193257072.0000\n",
            "Epoch 185/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 236570672.0000 - val_loss: 184053920.0000\n",
            "Epoch 186/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238997472.0000 - val_loss: 169996272.0000\n",
            "Epoch 187/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 232815024.0000 - val_loss: 162194352.0000\n",
            "Epoch 188/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 230685936.0000 - val_loss: 166857728.0000\n",
            "Epoch 189/800\n",
            "227/227 [==============================] - 1s 3ms/step - loss: 238766080.0000 - val_loss: 193304384.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "jG1I_-jh7fu0",
        "outputId": "15dde04c-8540-4236-dbb9-cb42d01ee9ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f93ff7d9490>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "prediction = estimator.predict(X_test)\n",
        "print(\"r_square score: \", r2_score(y_test,prediction))\n",
        "#y_test = sc2.inverse_transform(y_test.reshape(-1,1))\n",
        "yy = np.array(y_test)\n",
        "#prediction = sc2.inverse_transform(prediction.reshape(-1,1))\n",
        "predd = np.array(prediction)\n",
        "for i in range(len(yy)):\n",
        "  if(yy[i]-predd[i] > 99000):\n",
        "    print(\"real value of y_test: \" + str(yy[i]) + \" -> the predict: \" + str(predd[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnQXNvh3-rVR",
        "outputId": "f4243eab-f051-4503-b5ea-1eab3ca50138"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 1ms/step\n",
            "r_square score:  0.8894666314449334\n",
            "real value of y_test: 99999.0 -> the predict: 32.36532\n",
            "real value of y_test: 99999.0 -> the predict: 17.935902\n",
            "real value of y_test: 99999.0 -> the predict: 18.386845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "print(\"RMSE:\")\n",
        "sqrt(mean_squared_error(yy, predd)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSyzIFK5uzHP",
        "outputId": "eab8ac59-5351-456d-d376-276bab9dd2fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12540.726634610197"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}
